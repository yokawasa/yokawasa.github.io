<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Yoichi Kawasaki</title>
<meta name=keywords content><meta name=description content="Posts - Yoichi Kawasaki"><meta name=author content="Yoichi Kawasaki"><link rel=canonical href=https://unofficialism.info/posts/><link crossorigin=anonymous href=https://unofficialism.info/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://unofficialism.info/profile.jpg><link rel=icon type=image/png sizes=16x16 href=https://unofficialism.info/profile.jpg><link rel=icon type=image/png sizes=32x32 href=https://unofficialism.info/profile.jpg><link rel=apple-touch-icon href=https://unofficialism.info/profile.jpg><link rel=mask-icon href=https://unofficialism.info/profile.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://unofficialism.info/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Posts | Yoichi Kawasaki"><meta property="og:description" content="Yoichi Kawasaki yokawasa.github.io"><meta property="og:type" content="website"><meta property="og:url" content="https://unofficialism.info/posts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts | Yoichi Kawasaki"><meta name=twitter:description content="Yoichi Kawasaki yokawasa.github.io"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://unofficialism.info/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://unofficialism.info accesskey=h title="Yoichi Kawasaki (Alt + H)">Yoichi Kawasaki</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://unofficialism.info/about title=about><span>about</span></a></li><li><a href=https://unofficialism.info/posts title=posts><span class=active>posts</span></a></li><li><a href=https://unofficialism.info/works title=works><span>works</span></a></li><li><a href=https://unofficialism.info/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://unofficialism.info/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://unofficialism.info>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>Making SSH lives in Azure easier with azuresshconfig</h2></header><div class=entry-content><p>UPDATED 2016-10-31: paramsオプション + Bash Completion追加
みんな大好きSSHとAzureのお話し。物理サーバ、EC2/仮想マシン、コンテナなどなんでもよいがその上にLinuxサーバをたてたらまずやることの1つにSSHログインのためにそのIPアドレス調べて~/.ssh/configにそのエントリーを追加してやることがあるんじゃないかと思います。この作業、エントリー数が少なければ大したことはないものの、追加対象のホストが大量にある場合はかなり面倒な作業になってきます。さらにDHCPなどでアドレスを動的に取得するような設定であればサーバの上げ下げのたびにIPアドレスが変わってくるので~/.ssh/configの更新が必要になってきて、どうしようもなく面倒になってきます。こういった単純でどうしようもなくつまらない作業は自動化したいですよね？ ここではそんな皆さんのためにazuresshconfigというツールを紹介させていただきます。
これは皆さんのAzureサブスクリプション下に作られた仮想マシン一覧（ARMに限る）の情報を取得して各仮想マシンごとのエントリー情報（マシン名とIPアドレス）を~/.ssh/configに追加・更新してくれるツール。新規に仮想マシンを追加した際や、仮想マシンのIPアドレスが追加した際にはazuresshconfigを実行してあげることで~/.ssh/configが最新のエントリー情報でアップデートされ、各マシンにマシン名でSSHログインできるようになります。
ちなみに、~/.ssh/configとは何ですか？という人はQiitaの記事「~/.ssh/configについて」がとても分かりやすく書かれているので参考になるかと。
インストール Pythonパッケージ管理ツールpipを使ってazuresshconfigをインストールしてください。インストール時に何かエラーが発生した場合は、こちらのページを参照いただき特に該当する事象がないか確認ください。
$ pip install azuresshconfig 設定ファイルの編集（サービスプリンシパル） $ vi $HOME/.azure/azuresshconfig.json { "subscription_id": "", "client_id": "", "client_scret": "", "tenant_id": "" } サービスプリンシパルを作る必要があります。サービスプリンシパルの作り方が分からない人、とってもよいドキュメントがあります。こちらを参照ください：「Use Azure CLI to create a service principal to access resources」
使い方 azuresshconfig --help usage: azuresshconfig.py [-h] [--version] [--init] [--profile PROFILE] [--user USER] [--identityfile IDENTITYFILE] [--private] [--resourcegroups RESOURCEGROUPS] [--params PARAMS] This program generates SSH config from Azure ARM VM inventry in subscription optional arguments: -h, --help show this help message and exit --version show program's version number and exit --init Create template client profile at $HOME/....</p></div><footer class=entry-footer>&lt;span title='2016-10-13 00:00:00 +0000 UTC'>October 13, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Making SSH lives in Azure easier with azuresshconfig" href=https://unofficialism.info/posts/azuresshconfig/></a></article><article class=post-entry><header class=entry-header><h2>embulk plugins for Microsoft Azure Services</h2></header><div class=entry-content><p>Here is a list of embulk plugins that you can leverage to transfer your data between Microsoft Azure Services and various other databases/storages/cloud services.
Plugin Name Target Azure Services Note embulk-output-azure_blob_storage Blob Storage Embulk output plugin that stores files onto Microsoft Azure Blob Storage embulk-input-azure_blob_storage Blob Storage Embulk input plugin that reads files stored on Microsoft Azure Blob Storage embulk-output-sqlserver SQL Databases, SQL DWH Embulk output plugin that Inserts or updates records to SQL server type of services like SQL DB/SQL DWH embulk-input-sqlserver SQL Databases, SQL DWH Embulk input plugin that selects records from SQL type of services like SQL DB/SQL DWH embulk-output-documentdb Comos DB Embulk output plugin that dumps records to Azure Cosmos DB embulk-output-azuresearch Azure Search Embulk output plugin that dumps records to Azure Search (as of Aug 30, 2016)...</p></div><footer class=entry-footer>&lt;span title='2016-09-01 00:00:00 +0000 UTC'>September 1, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to embulk plugins for Microsoft Azure Services" href=https://unofficialism.info/posts/embulk-plugins-for-microsoft-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>fluent-plugin-documentdb supports Partitioned collections</h2></header><div class=entry-content><p>I’d like to announce fluent-plugin-documentdb finally supports Azure DocumentDB Partitioned collections for higher storage and throughput. If you’re not familiar with fluent-plugin-documentdb, read my previous article before move on.
Partitioned collections is kick-ass feature that I had wanted to support in fluent-plugin-documentdb since the feature came out public (see the announcement). For big fan of fluent-plugin-documentdb, sorry for keeping you waiting for such a long time :-) If I may make excuses, I would say I haven’t had as much time on the project, and I had to do ruby client implementation of Partitioned collections by myself as there is no official DocumentDB Ruby SDK that supports it (As a result I’ve created tiny Ruby DocumentDB client libraries that support the feature....</p></div><footer class=entry-footer>&lt;span title='2016-08-20 00:00:00 +0000 UTC'>August 20, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to fluent-plugin-documentdb supports Partitioned collections" href=https://unofficialism.info/posts/fluent-plugin-documentdb-supports-partitioned-collections/></a></article><article class=post-entry><header class=entry-header><h2>Collecting logs into Azure DocumentDB using fluent-plugin-documentdb</h2></header><div class=entry-content><p>In this article, I’d like to introduces a solution to collect logs and store them into Azure DocumentDB using fluentd and its plugin, fluent-plugin-documentdb.
Azure DocumentDB is a managed NoSQL database service provided by Microsoft Azure. It’s schemaless, natively support JSON, very easy-to-use, very fast, highly reliable, and enables rapid deployment, you name it. Fluentd is an open source data collector, which lets you unify the data collection and consumption for a better use and understanding of data....</p></div><footer class=entry-footer>&lt;span title='2016-02-21 00:00:00 +0000 UTC'>February 21, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;5 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Collecting logs into Azure DocumentDB using fluent-plugin-documentdb" href=https://unofficialism.info/posts/collecting-logs-into-azure-documentdb-using-fluent-plugin-documentdb/></a></article><article class=post-entry><header class=entry-header><h2>fluentd plugins for Microsoft Azure Services</h2></header><div class=entry-content><p>UPDATED:
2016-12-10: Added fluent-plugin-azure-loganalytics to the list 2016-11-23: Added fluent-plugin-azurefunctions to the list Here is a list of fluentd plugins for Microsoft Azure Services.
Plugin Name Target Azure Services Note fluent-plugin-azurestorage Blob Storage Azure Storate output plugin buffers logs in local file and upload them to Azure Storage periodicall fluent-plugin-azureeventhubs Event Hubs Azure Event Hubs buffered output plugin for Fluentd. Currently it supports only HTTPS (not AMQP) fluent-plugin-azuretables Azure Tables Fluent plugin to add event record into Azure Tables Storage fluent-plugin-azuresearch Azure Search Fluent plugin to add event record into Azure Search fluent-plugin-documentdb Cosmos DB Fluent plugin to add event record into Azure Cosmos DB fluent-plugin-azurefunctions Azure Functions Azure Functions (HTTP Trigger) output plugin for Fluentd....</p></div><footer class=entry-footer>&lt;span title='2016-02-16 00:00:00 +0000 UTC'>February 16, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to fluentd plugins for Microsoft Azure Services" href=https://unofficialism.info/posts/fluentd-plugins-for-microsoft-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>My patents</h2></header><div class=entry-content><p>I’ve just noticed that some of patents, which I was involved in for its publishing process, have been granted. Good news!
特開2011-065245 特開2011-065244 特開2011-065243 特開2011-060094 特開2011-060093 特開2008-287407</p></div><footer class=entry-footer>&lt;span title='2015-12-23 00:00:00 +0000 UTC'>December 23, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to My patents" href=https://unofficialism.info/posts/patents/></a></article><article class=post-entry><header class=entry-header><h2>ARMテンプレートを使って3分でAzure上にElasticsearchクラスタを構築する</h2></header><div class=entry-content><p>これはElasticsearch Advent Calendar 2015の17日目のエントリー
ARMテンプレートと呼ばれるデプロイ手法を使ってAzure上にElasticsearchクラスタをさくっと構築する方法についてのお話で、主にAzure界隈のElasticsearchユーザ向けの内容となっている。タイトルにある3分でというのは実際に計ったわけではないがそれくらい簡単且つ短時間でできることを強調したく使わせていただいている・・・ということを前もって補足しておく（汗）。
ARMテンプレートとは？ ARMテンプレートの前にARMについて少し解説する。ARMはAzure Resource Managerの略で、アプリケーション構築に必要な
リソース（ストレージ、ネットワーク、コンピュート/仮想マシンなど）をデプロイし管理するための仕組みである。どんなソリューションのデプロイにおいても少なからず仮想ネットワーク、仮想マシン、ストレージ、LBなどのインフラの構築が必要で旧来のやり方ではこれらを１つ１つデプロイしていたかと思う。一方ARMの世界では必要な構築要素をリソースという単位にして、これらリソースを個別にデプロイするのではなく全てのリソースをグループ化してまとめてデプロイし、それらを管理・監視することができる。そして、それら複数のリソースはJSON形式のテンプレートで表現・展開できるようになっていて、このテンプレートのことをARMテンプレートと呼ぶ。Infrastructure as Codeなんて言葉がはやっていたりするが、まさにそれをAzureで実現するための公式な仕組みがARMであり、ARMテンプレートなのである。
ちなみにこのARMテンプレート、手でいちから作る必要はなく、Azureクイックスタートテンプレートにさまざまなテンプレートが公開されているのでまずは自分の目的に似たようなことを実現しているテンプレートを選んでデプロイしてみることをお勧めする。完成されたものを見ることでお作法が学べるし、それをベースにカスタマイズしていくのが効率的である。
https://azure.microsoft.com/ja-jp/documentation/templates/ https://github.com/Azure/azure-quickstart-templates Elasticsearchクラスタのデプロイ 上記で説明したARMテンプレートを利用してElasticsearchクラスタのデプロイを行う。ここで使うARMテンプレートはAzureクイック・スタートテンプレートギャラリーにあるElasticsearchテンプレートを利用する。ARMテンプレートを使ったデプロイには複数の方法があるがここではLinux上でAzure CLIを使った方法で行う。ここでの実行OSはUbuntu 14.10。
最新版のAzure CLIをインストールしてからAzureサブスクリプションに接続する
$ sudo npm install -g azure-cli $ azure --version $ azure login 「Azure コマンド ライン インターフェイス (Azure CLI) からの Azure サブスクリプションへの接続」に書かれているように、Azure CLI バージョン 0.9.10 以降では、対話型の azure login コマンドを使用して、任意の ID でアカウントにログインできる。尚、バージョン 0.9.9 以降は、多要素認証をサポートしている。
デプロイ用のリソースグループを作成する
ここでは西日本（Japan West）リージョンにResource-ES-JapanWestという名前のリソースグループを作成する。
# azure group create -n "&lt;リソースグループ名>" -l "&lt;リージョン名>" $ azure group create -n "Resource-ES-JapanWest" -l "Japan West" ARMテンプレートのダウンロードとパラメータの編集...</p></div><footer class=entry-footer>&lt;span title='2015-12-17 00:00:00 +0000 UTC'>December 17, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to ARMテンプレートを使って3分でAzure上にElasticsearchクラスタを構築する" href=https://unofficialism.info/posts/deploy-elasticsearch-cluster-in-azure-using-arm-template/></a></article><article class=post-entry><header class=entry-header><h2>今一度Traffic Managerのエンドポイント監視について</h2></header><div class=entry-content><p>Azureが提供するDNSによるトラフィックルーティングサービスであるTraffic Managerについて、既にAzure利用ユーザに使い尽くされて新鮮味に欠けるサービスではあるものの、そのエンドポイント監視はTraffic Managerを扱う上でとても重要なことなので今一度そのルールについて整理したい。
Traffic managerの実態はエンドポイントの監視＋ルーティングを行うDNSサービスである。以下digの結果を見ていただいてわかる通りyoichika-demo1.trafficmanager.netという外向きの名前に対してこの時点ではwebappdemo3.cloudapp.netがCNAMEされている。Traffic Managerは利用ユーザが設定したエンドポイントを監視し、その結果に応じて適切なルーティングを行う。ルーティング方法にはフェールオーバー、ラウンドロビン、パフォーマンスの3通りがある。これについて詳しくは「Traffic Managerのルーティング方法」を参照いただきたい。
; &lt;&lt;>> DiG 9.9.5-4.3ubuntu0.1-Ubuntu &lt;&lt;>> yoichika-demo1.trafficmanager.net +noall +answer ;; global options: +cmd yoichika-demo1.trafficmanager.net. 30 IN CNAME webappdemo3.cloudapp.net. webappdemo3.cloudapp.net. 60 IN A 70.37.93.167 次に肝心のエンドポイントの監視について「Traffic Manager の監視について」の監視シーケンスを使って要点を整理する。
エンドポイントへのProbe送信(ハートビート)は30ごとに実行 ProbeはHTTP 200 OKかどうかで判定 4回連続して失敗が続いた後、監視システムは使用不可のクラウドサービスを使用不可とみなしそのエンドポイントにトラフィックのルーティングを行わない(④にあたる。⑥は後述) DNS の有効期限 (TTL) によりDNSリゾルバーで解決された名前がDNS サーバー上でキャッシュされている期間使用できないサービスの DNS 情報を引き続き配信してしまう⇒トラフィック減少期間 (⑥にあたる)。DNSのTTLの既定値は、300秒(5分) つまり、エンドポイントがダウンした場合、Probeにより使用不可とみなすのに最大120秒(30秒 x 4)、さらにDNSのTTLの期間（既定値は300秒）を加えると、完全に問題のあったエンドポイントへのトラフィックが停止するまでに標準的に420秒、約7分は見ておく必要があるということになる。当然ながらこの7分間トラフィックがロスする可能性があるため、俊敏なフェールオーバーを期待する場合は別の仕掛けを用意する必要がある。ご注意ください。</p></div><footer class=entry-footer>&lt;span title='2015-11-29 00:00:00 +0000 UTC'>November 29, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to 今一度Traffic Managerのエンドポイント監視について" href=https://unofficialism.info/posts/traffic-manager-endpoint-monitoring/></a></article><article class=post-entry><header class=entry-header><h2>Static linking DLL to EXE in C Sharp</h2></header><div class=entry-content><p>Q1. C Sharpでexeに複数DLLをスタティックリンクさせて１ファイルにすることはできますか？
C、C++ではおなじみのスタティックリンクだが、そもそもC Sharpではスタティックリンクができない。ただし
MS Research謹製のILMergeを使えば実行ファイル(exe)に対して複数のクラスアセンブリ(DLL)を１つのアセンブリにマージすることはできる。使い方はこちらが参考になる。また、ILMerge-GUIというGUIツールもある。
Q2. Visual Studioのビルドでも自動的に複数ファイルを１つにまとめることはできますか？
パッケージマネージャーでILMerge.MSBuild.Tasksをインストールして*.csprojファイルに自動アセンブリ生成するための設定を追記するとVSのビルドで複数ファイルが１つのアセンブリにマージされたファイルが自動的にできあがる。参考: StackOverflow 「How to Integrate ILMerge into Visual Studio Build Process to Merge Assemblies?」
ILMerge.MSBuild.Tasksをインストール Install-Package ILMerge.MSBuild.Tasks *.csprojファイルに下記設定を追記 &lt;!-- Code to merge the assemblies into one --> &lt;UsingTask TaskName="ILMerge.MSBuild.Tasks.ILMerge" AssemblyFile="$(SolutionDir)\packages\ILMerge.MSBuild.Tasks.1.0.0.3\tools\ILMerge.MSBuild.Tasks.dll" /> &lt;Target Name="AfterBuild"> &lt;ItemGroup> &lt;MergeAsm Include="$(OutputPath)$(TargetFileName)" /> &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名1" /> &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名2" /> ... &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名N" /> &lt;/ItemGroup> &lt;PropertyGroup> &lt;MergedAssembly>出力する結果アセンブリファイル名（フルパス）&lt;/MergedAssembly> &lt;/PropertyGroup> &lt;Message Text="ILMerge @(MergeAsm) -&amp;gt; $(MergedAssembly)" Importance="high" /> &lt;ILMerge InputAssemblies="@(MergeAsm)" OutputFile="$(MergedAssembly)" TargetKind="SameAsPrimaryAssembly" /> &lt;/Target> &lt;/Project> VSビルド実行で、マージされたファイルが生成（*....</p></div><footer class=entry-footer>&lt;span title='2015-09-09 00:00:00 +0000 UTC'>September 9, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Static linking DLL to EXE in C Sharp" href=https://unofficialism.info/posts/tips-visual-studio-csharp-merge-exe-and-dll/></a></article><article class=post-entry><header class=entry-header><h2>SOCKSプロキシを経由したAzure VNETプライベートリソースへのアクセス</h2></header><div class=entry-content><p>UPDATED 2017-03-22: Added SOCKS Proxy Configuration for Internet Explorer
外部からの接続（SSH、HTTPなど）を受け付けていないAzure 仮想ネットワーク(以下VNET)内のリソースにSOCKSプロキシを経由して外部からアクセスしましょうというお話。本記事ではAzure VNET内の外部からのアクセス許可していないVMへのSSHログインとHTTPサーバコンテンツへのブラウジングの2つの方法を紹介する。
SOCKS(RFC1928) とはさまざまなアプリケーションが間にファイアーウォールを挟んでいても安全に快適にやり取りができるようにすることを目的として作られたプロトコルのことで、SOCKSプロキシはSOCKSプロトコルを受け取りファイアウォール内外との接続を可能にするものである。エンドポイントやNetwork Security Group (NSG)によりネットーワーク分離設定されたAzure VNET内のリソースに対して一時的に本来直接アクセス許可しないネットワークからアクセスが必要な状況はあるかと思う。そのような時に毎回設定変更で必要なプロトコル、アクセス先に対して穴をあけるのは非常に面倒であり、またサイト間VPN、ポイント対サイトVPNとなるとさらに手間がかかる。お手軽に、もしくは定常的ではないが一時的に内部リソースにアクセスしたい場合にSOCKSプロキシ経由でのアクセスを検討してみてはいかがだろうか。以下はSOCKSプロキシ経由によるAzure VNET内のプライベートリソースへのアクセスイメージである。
SOCKSプロキシの作成 まずはOpenSSHのダイナミックポートフォワード機能を使ってSOCKSプロキシを作成する。ダイナミックポートフォワードはSSHをSOCKSプロキシとして振舞うことを可能にする。SSHでアクセス先ホストと DynamicFoward(-D)でポートを指定することでlocalhostにSOCKSプロキシが立ち上がり指定のTCPポート(SOCKSプロキシサーバは基本的は1080だが、割り当て可能なポートであればどのポートでもOK)をlocalhost側からログイン先ホストのSSHサーバに転送することができるようになる。もちろん経路は暗号化される。現状のサポートプロトコルはSOCKS4とSOCKS5。
例えば上図でいうとJump Server(踏み台)にDynamicFoward(-D)1080でログインすると、Jump Serverにポート1080を転送するSOCKSプロキシが localhostに立ち上がり、そのlocalhost:1080に対してSOCKS4またはSOCKS5プロトコルで接続することでJump Serverを経由して通信を行うことができるようになる。
localhostポート1080のJump Serverへのダイナミックフォワードは次のように-Dオプションで行う。
$ ssh -2 -D 1080 -l [Account] [Jump Server] 毎回-Dオプション指定が面倒な場合は、次のようにconfg(ssh_config)にDynamicForwardの記述することも可能。
~/.ssh/config
Host JumpServer User [Account名] HostName/IP [Jump Serverホスト/IPアドレス] Protocol 2 ForwardAgent yes DynamicForward 1080 上記OpenSSHの設定は、Linux/Macの場合は標準Terminalを使えばよいが、Windowsの場合はCygwin、XmingなどX端末エミュレータソフトをインストールしていただく必要がある。またX端末エミュレーターをインストールしなくともWindowsでは有名なSSHクライアントソフトPuttyがダイナミックポートフォワードに対応しているためPuttyを使ってSOCKSプロキシ作成することも可能。詳しくは「Dynamic Port Forwarding with SOCKS over SSH」が参考になるかと。
SOCKSプロキシを使ったSSH接続 次に上記で作成したSOCKSプロキシを経由してVNET内のサーバにSSH接続をする。 netcatでSOCKSプロキシを経由してlocalhostから目的のVNET内サーバ（ServerX）間にnetcatトンネルを作成してServerXにはそのnetcatトンネルを通じて接続する。
local$ ssh -2 -l [Account] -o 'ProxyCommand nc -x localhost:1080 %h %p' [ServerX] netcat のプロキシ指定は-xオプションで行う。 ここでは事前に作成したSOCKSプロキシ(localhost:1080)を指定。 netcatトンネルの作成コマンドはProxyCommandに記述する。こちらも毎回長いオプション入力を避けるために config（ssh_config）設定すると便利である。...</p></div><footer class=entry-footer>&lt;span title='2015-08-18 00:00:00 +0000 UTC'>August 18, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to SOCKSプロキシを経由したAzure VNETプライベートリソースへのアクセス" href=https://unofficialism.info/posts/accessing-private-resource-in-azure-vnet-via-socks-proxy/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://unofficialism.info/posts/page/3/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://unofficialism.info/posts/page/5/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://unofficialism.info>Yoichi Kawasaki</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>