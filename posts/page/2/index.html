<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | unofficialism</title>
<meta name=keywords content><meta name=description content="Posts - unofficialism"><meta name=author content="Yoichi Kawasaki"><link rel=canonical href=https://yokawasa.github.io/posts/><link crossorigin=anonymous href=https://yokawasa.github.io/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://yokawasa.github.io/profile.png><link rel=icon type=image/png sizes=16x16 href=https://yokawasa.github.io/profile.png><link rel=icon type=image/png sizes=32x32 href=https://yokawasa.github.io/profile.png><link rel=apple-touch-icon href=https://yokawasa.github.io/profile.png><link rel=mask-icon href=https://yokawasa.github.io/profile.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://yokawasa.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://yokawasa.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Posts | unofficialism"><meta property="og:description" content="Yoichi Kawasaki yokawasa.github.io"><meta property="og:type" content="website"><meta property="og:url" content="https://yokawasa.github.io/posts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts | unofficialism"><meta name=twitter:description content="Yoichi Kawasaki yokawasa.github.io"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yokawasa.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yokawasa.github.io/ accesskey=h title="unofficialism (Alt + H)">unofficialism</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://yokawasa.github.io/about title=about><span>about</span></a></li><li><a href=https://yokawasa.github.io/posts title=posts><span class=active>posts</span></a></li><li><a href=https://yokawasa.github.io/works title=works><span>works</span></a></li><li><a href=https://yokawasa.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://yokawasa.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://yokawasa.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>Azure Functions Python Programming - Experimental</h2></header><div class=entry-content><p>今年もあと少し。ほぼ趣味の範囲を超えないレベルで今年取り組んだテーマの１つにAzure Functions with Pythonがある。あまり情報が無い中、興味本位でサンプルコードを作っては動かして試して得られた情報をシコシコとGithubに上げているうちにナレッジが溜まって来た。それほど多くはないと思うがPythonでAzure Functionsアプリを作りたいという人もいると思うのでノウハウをブログにまとめておく。いきなり水を差すようではあるが、現時点（2017年12月）ではAzure FunctionsのPythonサポータビリティはExperimental（実験的サポート）でありプロダクション向きではない状況であるので、ホントにPythonが好きな人がOn your own riskで楽しんでいただければと思う。
Azure FunctionsのPythonサポート状況 Azure FunctionsのRuntimeには大きく1系と２系の２種類あるが、現時点でPythonは1系でのみExperimentalサポートという状況（ See also 言語サポート状況）
Experimental（実験的サポート）なので本番での利用は非推奨であり、公式サポートはない（ベストエフォートでのサポートは得られるはず）。また、当然ながらGA言語に比べパフォーマンスは悪い。PythonはFunction呼び出し毎にpython.exeが実行される（GA言語はRuntimeと同じプロセスで実行）。
将来的な話をすると、Azure Functions Runtime 1系でのPythonサポートについては今のExperimentalの域を超えることはないだろう。一方、Runtime 2系ではPythonが正式サポートされるように対応が進められている。ただし時期は未定。この対応については下記Github Issueが切られており、ある程度の対応状況であれば確認可能。Pythonを使う利点の１つに、強力な数理計算、自然言語解析、機械学習系モジュールがあるが、早く安定とパフォーマンスが備わったPythonサーバレスアプリ実行環境でこれら強力なモジュールを活用できたらと思うのは私だけではないだろう。今後の進展に期待。
Feature planning: first class Python support Hosting Planの選択について Consumption Plan vs App Service Plan Azure FunctionsのHosting PlanにはConsumption PlanとApp Service Planの2つがあって、言語に関係なく各プランの特徴は次の通り:
Consumption Plan
コード実行時にコンピューティング割り当て リソース使用量（関数実行時間、使用メモリ）で課金 自動スケール、各処理は〜10分まで App Service Plan
専用VMでリソース確保 継続処理：10分以上の処理 App Service環境でのみ可能な処理: App Service Environment, VNET/VPN接続, より大きなサイズのVM, etc Pythonで使う上で気をつけるポイント Python 3.XなどRuntimeの変更を行う場合は、専用環境である必要があってApp Service Plan必須 Consumption Planの場合、Pythonに限らずColdスタート問題という休眠したFunctionの起動が極端に遅くなる問題があるのだが、Pythonの場合は、GA言語に比べてパフォーマンスが悪く、SciPyなど重めのモジュールを利用すると絶望的に遅くなることからConsumption Planでの問題が特に顕著にでてくる。これまでの経験から、小さいインスタンスを並べるConsumption Planよりも比較的大きなサイズのVMが選べるApp Service Planの方が向いていることが多い。Pythonの場合は、予測可能なワークロードに対してApp Service Planで使うほうが問題が少ない。Consumption Planの魅力であるMicro Billing（使った分だけ課金）やリクエストに応じたオートスケーリングといった真のサーバレスに期待される要件は既に正式サポートしているC#、Nodeでやっていただくのがよいかと。 [参考] Coldスタート問題 Consumption Planにおける問題 Azure Functions Cold Start Workaround The only downside is that the consumption model that keeps the cost so dirt-cheap means that unless you are using your Function constantly (in which case, you might be better off with the non-consumption options anyway), you will often be hit with a long delay as your Function wakes up from hibernation 休眠したFunctionをどう起こすかがポイント。事前に空リクエストを送ることが考えられるが問題はタイミング（フォーム開いた時とか） Python 3....</p></div><footer class=entry-footer>&lt;span title='2017-12-29 00:00:00 +0000 UTC'>December 29, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Azure Functions Python Programming  - Experimental" href=https://yokawasa.github.io/posts/azure-functions-app-development-with-python-experimental/></a></article><article class=post-entry><header class=entry-header><h2>Developing Full Managed Search Application in Azure</h2></header><div class=entry-content><p>これは9/29 Azure Web Seminar 「Azure サービスを活用して作るフルマネージドな全文検索アプリケーション」のフォローアップ記事です。なかなか暇ができず少々時間が経過してしまいました。
Azure サービスを活用して作るフルマネージドな全文検索アプリケーション from Yoichi Kawasaki
Sample Application & Source Code セミナーで紹介したサンプルアプリはAzure公式サイトに載せてある代表的なサービスのFAQデータを元にしたHTML/CSS/JavascriptによるQ＆Aナレジッジベース検索のシングルページアプリケーションです。検索エンジンにAzure Searchを使い、データソースにCosmos DBを使いAzure SearchのCosmosDB Indexerでクローリングする構成にしてます。ソースコードと設定手順は以下Githubプロジェクトにアップしてあります。もしバグや設定手順等でご質問があればGithubでIssue登録いただければ時間を見つけて対応させていただきます。
Source Code: https://github.com/yokawasa/azure-search-qna-demo/
Demo: AI Digital Media Search セミナー中に紹介した非構造化データの全文検索デモとして紹介したAI Digital Media Searchアプリケーション。メディア x 音声認識 x 機械翻訳 x 全文検索全てを絡めた面白いアプリケーションなのでこちらでデモ動画とソースコードを共有します。またこのアプリはAzure PaaSサービスを組み合わせてプレゼンテーションレイヤー(Web App for Container)のみならずデータ生成部分（AMS, Functions, Logic App）も全てサーバレスで実現しているのでこのエリアのサンプルアプリとしてもとても良いものになっていると思います。
Demo Video: AI Digital Media Search Demo Source Code: https://github.com/shigeyf/ai-digitalmedia AzureSearch.js - Azure Search UIライブラリ AzureSearch.jsはAzure SearchのUIライブラリで、Azure Searchプロダクトチーム主要開発者により開始されたOSSライブラリです。TypeScriptで書かれているのでとても読みやすく、また、ライブラリが提供するオブジェクト操作により非常に短いコードでサーチボックス、結果出力、ページネーション、ファセット、サジェスションなどで構成されるサーチ用UIを簡単に組み立てることが可能です。なかなかいけているライブラリにもかかわらず、あまり世の中に知られていないのはもったいないと思いセミナーの最後で紹介させていただきました。これ使わない手はないです。手っ取り早くは、下記のAzureSearch.jsアプリテンプレートジェネレータページで皆さんのAzure SearchアカウントのQueryKeyとインデックススキーマ（JSONフォーマット）を入力するとAzureSearch.jsアプリの雛形が生成されますので、そこから始めるのがよいかと思います。
AzureSearch.jsプロジェクトトップ＠Github デモアプリサイト AzureSearch.jsアプリのテンプレートジェネレータ END</p></div><footer class=entry-footer>&lt;span title='2017-10-22 00:00:00 +0000 UTC'>October 22, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Developing Full Managed Search Application in Azure" href=https://yokawasa.github.io/posts/building-full-text-search-application-using-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>Azure Search Text Analyzer Tools - azure-search-ta</h2></header><div class=entry-content><p>Azure Searchのアナライザーによるテキスト解析結果を出力する（だけの）ツールを作ってみたのでここで紹介します。その名もazure-search-ta（ta=Test Analyzer）。中身はAzure SearchのAnalyzer APIの出力結果を整形して表示させていているだけの単純なものでありますが、Azure Searchの全文検索チューニングやキーワードにヒットしない原因調査をする際には役に立つと思ってます。「どうしてこのキーワードがひっかからないの？」を突き詰めるには最終的にアナライザのテキスト解析結果と突き合わせる必要があるのと、アナライザーを選択する際にテキスト解析が視覚化されていると判断しやすいだろうと。ツールは2種類で （１）Web UIツールと（２）コマンドラインツール
Web UI Tool https://github.com/yokawasa/azure-search-ta
インストールは超簡単。（１）Githubからazure-search-taをclone （２）azure-search-ta/ui 配下のファイルをPHPが動くWebサーバにコピー （３）analyze-api.phpをエディタで開いてお使いのAzure Searchカウント名とAzure Search API Adminキーの値を設定ください。あとはazure-search-ta-ui.htmlにアクセスいただければ上記のようなUIが出力されるはずです。なぜHTML/JSだけではなく間にPHPを挟んでいるのかについて、Azure SearchのAnalyze APIや管理系APIリクエストに位置付けられており、管理系APIはvia CORSでのリクエストを受け付けていないからである。
$ git clone https://github.com/yokawasa/azure-search-ta.git` $ vi azure-search-ta/ui/analyze-api.php $azureSearchAccount=""; $azureSearchApiKey = ""; Command-Line Tool 1. インストールと設定 pipでazure-search-taパッケージをインストール。既に古いバージョンをインストール済みでアップデートする際は――upgradeをつけて実行ください。
$ pip install --user azure-search-ta 次に、search.confにお使いのAzure Searchカウント名とAzure Search API Adminキーの値を設定ください。
# Azure Search Service Name ( never put space before and after = ) SEARCH_SERVICE_NAME= # Azure Search API Admin Key ( never put space before and after = ) SEARCH_API_KEY= 2....</p></div><footer class=entry-footer>&lt;span title='2017-05-13 00:00:00 +0000 UTC'>May 13, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Azure Search Text Analyzer Tools - azure-search-ta" href=https://yokawasa.github.io/posts/azure-search-analyzer-test-with-azure-search-ta/></a></article><article class=post-entry><header class=entry-header><h2>Python Easter Egg</h2></header><div class=entry-content><p>Python Easter Egg = Pythonの隠しクレジットとはいってもPython基礎本などでよく紹介されているものなので既にご存知かもしれないが背景が面白いのでここで紹介。
Pythonにはthisモジュールという「The Zen of Python」(Note 1)を出力するだけのモジュールがある。このモジュール、中身(Note 2)を見てみると分かるが、総ステップにしてわずか28行、ROT13暗号化(Note 3)された文字列を復号化するだけの単純で取るに足らないものかもしれないがこのモジュールが作られた背景は面白い。Barry Warsaw氏が記事「import this and The Zen of Python」でthisモジュールが誕生にまつわる面白い話を紹介している。
「import this and The Zen of Python」の一部簡訳
2001年秋、Foretec Seminar社はのInternational Python Conference #10(以下IPC10、Pyconの前身となるカンファレンス)の準備をしておりPythonコミュニティからそのカンファレンスのスローガンを求めていた。スローガンはTシャツにもプリントされる予定だった。Guideや、Fred、Jeremyや著者達はかつてはForetec Seminar社に所属していたがPythonlabsを結成する2000年に同社を去っている。そしてPythonlabsはPythonコミュニティからのスローガン応募の審査と勝者の選定を担当することになった。応募は500くらいあったが、どれもひどいものだった。Timと著者は1つに絞られるまで何度となく選別作業を行い
最終的に"import this"を選んだ。理由は"import this"という言葉の持つふざけた、小バカにしたようなトーンが好きだったからという。
著者たちはこの"import this"をスローガンに選んですぐにthisモジュール(this.py)を実装した。モジュールは「The Zen of Python」を出力するだけのものだったが途中TimやGuidoの提案でrot13で暗号化して内容を少し難読化する工夫がされたりもした。IPC10が終わってすぐ、彼らはこのイベントを記念してthisモジュールをPython2.2.1ブランチにコミットした。この時、著者の提案で他の誰にも知られないようにするためにソース管理システムのチェックイン通知機能を停止し、こっそりこのモジュールをPython2.2.1のブランチに含めたのだ。これらのことは彼ら以外に誰にも知らせず内緒で行われた。著者いわく、この彼らの仕込んだeaster egg（thisモジュールのこと。ソフトウェアでいうeaster eggとは隠しコマンドとか、隠しクレジットのようなもの）が誰かに見つかるまではしばらく時間がかかったそうだ。
Barry Warsaw氏が同記事を「That was all back in the day when the Python community had a sense of humor」という一文で締めくくっているように、この記事を読むと当時のPythonコミュニティがいかにユーモア溢れたものだったのかが感じられる。phython-2.2.1がリリースされたのは2002年4月10日で、それからどれくらい経ってこのthisモジュールが発見されたのか分からないが初めて発見した人は絶対ほっこりしたことだろう。
Note 1: import this 「The Zen of Python」はPythonハッカー、Tim Petersによって書かれた有名な文章でPython設計哲学を要約したようなものと言われている。 Barry Warsaw氏の記事によると起源はTim Peters氏による1999年6月4日のPython-listへのこの投稿のようだ。以下、Pythonインタラクティクモードでimport thisを実行し「The Zen of Python」を表示させた内容：...</p></div><footer class=entry-footer>&lt;span title='2017-05-13 00:00:00 +0000 UTC'>May 13, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;4 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Python Easter Egg" href=https://yokawasa.github.io/posts/python-easter-egg/></a></article><article class=post-entry><header class=entry-header><h2>azuresshconfig has been dockerized</h2></header><div class=entry-content><p>UPDATED 2017-02-15: changed docker run command example due to Issue#4
以前「azuresshconfigの紹介 – Azure上でのSSH生活を少しだけ快適にする」の投稿でazuresshconfigの紹介をさせていただいたが、ツールをリリースして以来、数少ない貴重な利用者様からインストールがコケるんだけど何とかしろというクレームをいただいていた。そこでインストールマニュアルを充実させようかとか、インストーラーをプラットフォーム別に充実させようかとか考えたものの、ここは流行りのコンテナ実行できるようしたほうがいいだろうということでDocker対応することにした。
今回の対応によりpipインストールや、プラットフォーム別にprerequisiteなランタイム、ヘッダファイル、ライブラリといった面倒なインストールが不要となり、Mac、Windows、Linux(Ubuntu、CentOS、その他distro)関係なくシンプルにdocker runコマンドでの実行が可能となった。
しかも超軽量LinuxディストリビューションであるAlpine Linuxの上にPythonランタイムとツールを載せているだけであるためサイズはたったの155MBとかなり軽め
$ docker images azuresshconfig REPOSITORY TAG IMAGE ID CREATED SIZE azuresshconfig latest 7488bef4343f 7 minutes ago 155 MB 実行例 $ docker run -v $HOME:/root --rm -it yoichikawasaki/azuresshconfig \ --output stdout --user yoichika --identityfile ~/.ssh/id_rsa > $HOME/.ssh/config Dockerfileをダウンロードしてビルド・実行はこちら
$ curl https://raw.githubusercontent.com/yokawasa/azure-ssh-config/master/Dockerfile -o Dockerfile $ docker build -t azuresshconfig . $ docker run -v $HOME:/root --rm -it yoichikawasaki/azuresshconfig \ --output stdout --user yoichika --identityfile ~/....</p></div><footer class=entry-footer>&lt;span title='2017-02-05 00:00:00 +0000 UTC'>February 5, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to azuresshconfig has been dockerized" href=https://yokawasa.github.io/posts/azuresshconfig-has-been-dockerized/></a></article><article class=post-entry><header class=entry-header><h2>Logstash plugins for Microsoft Azure Services</h2></header><div class=entry-content><p>Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite destinations. Here is a list of logstash plugins for Microsoft Azure Services.
Plugin Name Target Azure Services Note logstash-input-azureeventhub EventHub Logstash input plugin reads data from specified Azure Event Hubs logstash-input-azureblob Blob Storage Logstash input plugin that reads and parses data from Azure Storage Blobs logstash-input-azuretopic Service Bus Topic Logstash input plugin reads messages from Azure Service Bus Topics logstash-input-azuretopicthreadable Service Bus Topic Logstash input plugin reads messages from Azure Service Bus Topics using multiple threads logstash-output-applicationinsights Application Insights Logstash output plugin that store events to Application Insights logstash-input-azurewadtable Table Storage Logstash input plugin for Azure Diagnostics....</p></div><footer class=entry-footer>&lt;span title='2016-12-29 00:00:00 +0000 UTC'>December 29, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Logstash plugins for Microsoft Azure Services" href=https://yokawasa.github.io/posts/logstash-plugins-for-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>Detecting faces in Video contents using Azure Cognitive Services Face API</h2></header><div class=entry-content><p>過去に本ブログでビデオコンテンツを切り口とした音声認識やOCR技術を利用したデモを紹介したが、ここではビデオコンテンツの中の人物出現箇所に連動して人物名を字幕で表示させるデモとその実装方法を紹介したい。人物識別にはAzureのCognitive ServicesのFace APIを使っていて、これで動画の中に出現する顔の検出を行い、予め登録している人物リストとのマッチングにより実現している。 Cognitive Serivcesとは視覚、音声、言語、知識などマイクロソフトがこれまで研究を通じて開発してきたさまざまな要素技術をAPIとして提供しているサービスのことで、最近巷で人工知能（AI）だとかインテリジェンスとかいうキーワードをよく耳にするのではないかと思うがAzure利用シナリオでそういったインテリジェンス（知能/知性）を兼ね備えたアプリを作る場合は間違いなく中核となるサービスの1つである。Face APIはその中でも顔の検出・識別や、顔にまつわる感情、特徴などメタデータ抽出に特化したAPIである。
demo site source code 主要テクノロジーと機能 下図は今回のデモ作成のために行っている処理フローと主要テクノロジーを表している。やっていることは大きく分けて3つ: (1) 動画コンテンツをAzure Media Encoder Standardを使ってフレームごとの静止画像の作成, (2) Cognitive ServicesのFace APIを使って1より得られた静止画像から顔の検出を行い予め登録している人物リストとマッチング（最も類似度が高いものを本人とみなす）して人物を識別, (3) 2で得られた各フレーム中の人物情報を時間順に並べて字幕(Closed Caption)用のデータファイルを生成。以下、各処理の詳細について説明する。
1. Azure Media Encoder Standardでフレームごとの静止画生成 残念ながらFace APIはビデオコンテンツから直接顔検出することができないため、一旦ビデオコンテンツから各フレームごとの静止画を生成してその静止画を対象に処理を行う必要がある。ここでは各フレームごとの静止画生成にAzure Media Encoder Standard（MES）を利用する。MESを使うことでエンコードタスクとしてビデオコンテンツに対して様々な処理を行うことができるのだが、MESにはそのエンコードタスクの１つとしてサムネイル生成のためのタスクが用意されており、今回はこのサムネール生成タスクを利用する。他のエンコードタスク同様にサムネイル生成タスクについてもプリセットと呼ばれるエンコードに必要な情報を記述した XML または JSON形式ファイルを用意する必要がある。今回は1秒フレームごとにJPEG形式の静止画（サムネイル）を生成するために次のようなプリセット（amsmp-thumbnail-config.json）を用意した。
{ "Version": 1.0, "Codecs": [ { "Start": "00:00:00", "Step": "00:00:01", "Type": "JpgImage", "JpgLayers": [ { "Quality": 90, "Type": "JpgLayer", "Width": 640, "Height": 360 } ] } ], "Outputs": [ { "FileName": "{Basename}_{Index}{Extension}", "Format": { "Type": "JpgFormat" } } ] } MESによるサムネイル処理実行方法やプリセットの詳細については「Media Encoder Standard を使用した高度なエンコード」や同ページの「サムネイルを生成する」項を参照ください。尚、今回のサムネイル生成のためのエンコーディング処理は小生自作の「azure-media-processor-java」を利用してバッチ実行している。...</p></div><footer class=entry-footer>&lt;span title='2016-12-18 00:00:00 +0000 UTC'>December 18, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Detecting faces in Video contents using Azure Cognitive Services Face API" href=https://yokawasa.github.io/posts/azure-media-cognitive-demos-video-frames-face-recognition/></a></article><article class=post-entry><header class=entry-header><h2>Collecting events into Azure Functions and triggering your custom code using fluent-plugin-azurefunctions</h2></header><div class=entry-content><p>In this article, I’d like to introduces a solution to collect events from various sources and send them into HTTP Trigger function in Azure Functions using fluent-plugin-azurefunctions. Triggers in Azure Functions are event responses used to trigger your custom code. HTTP Trigger functions allow you to respond to HTTP events sent from fluentd and cook them into whatever you want!
[note] Azure Functions is a (“serverless”) solution for easily running small pieces of code, or “functions,” in Azure....</p></div><footer class=entry-footer>&lt;span title='2016-11-27 00:00:00 +0000 UTC'>November 27, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;5 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Collecting events into Azure Functions and triggering your custom code using fluent-plugin-azurefunctions" href=https://yokawasa.github.io/posts/fluent-plugin-azurefunctions/></a></article><article class=post-entry><header class=entry-header><h2>Video OCR using Azure Media & Cognitive</h2></header><div class=entry-content><p>OCRとはOptical Character Recognitionの略で日本語にすると光学文字認識と訳されており、ざっくりと画像の中の文字をテキストに変換する技術のことを指す。テキストに変換されるということは勘が鋭い皆さんはお気づきだと思うが、テキストの全文検索であったり、テキストから音声への変換、さらには機械翻訳を使って多言語への変換といった展開が考えられる。そんな可能性を秘めたOCRであるが、ここではそのOCRの技術を使ってビデオファイルから抽出したテキストデータを元にビデオに字幕表示したり、動画中に表示される文字を全文検索をするデモを紹介したい。内容的には「Azure Media & Cognitiveデモ:Speech-To-Text」で紹介したデモのOCR版といったところ。
demo site source code 主要テクノロジーと機能 Azure Media OCRメディアプロセッサによるテキスト抽出 このデモではAzure Media OCRメディアプロセッサー(MP)を使用してビデオファイル内のテキストコンテンツを検出してテキストファイルを生成している。OCRメディアプロセッサーは入力パラメータによりビデオ解析の挙動を調整することができる。主なパラメータとしては検索対象テキストの言語（日本語もサポート）、テキストの向き、サンプリングレート、ビデオフレーム内のテキスト検出対象のリージョンがあるが、本デモでの入力パラメータ（Video-OCR-Search-Python/src/ocr-detectregion.json）は以下の通り検索対象言語は日本語、1秒おきのサンプリングレート、テキスト検出対象のリージョンからビデオフレーム内の上部1/4を省く設定（検出対象をフレームトップから85 pixel以下を対象）にしている。
{ "Version":"1.0", "Options": { "Language":"Japanese", "TimeInterval":"00:00:01.000", "DetectRegions": [ {"Left":"0","Top":"85","Width":"1280","Height":"635"} ] } } そして、Azure Media OCRメディアプロセッサはビデオで検出された文字を下記のような表示時間に基づいてセグメント化された形で結果出力する。結果ファイルの完全版はこちら（azuresubs.json）を参照ください。
{ "fragments": [ { "start": 0 "interval": 319319, "duration": 319319, "events": [ [ { "language": "Japanese", "text": "Azure の 契 約 内 容 を 変 更 す る Microsoft Azure" } ] ] }, { /* fragment1 */ }, { /* fragment2 */ }, ....</p></div><footer class=entry-footer>&lt;span title='2016-11-07 00:00:00 +0000 UTC'>November 7, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Video OCR using Azure Media & Cognitive" href=https://yokawasa.github.io/posts/azure-media-cognitive-demos-video-ocr/></a></article><article class=post-entry><header class=entry-header><h2>Speech-To-Text with Azure Media & Cognitive Services</h2></header><div class=entry-content><p>ビデオコンテンツを音声認識エンジンでテキスト化してそれを元にスピーチ検索するデモコンテンツを紹介したい。これは過去にde:code2016というマイクロソフトの開発者向けイベントで行ったブレイクアウトセッション「DEV-18: Azure Search Deep Dive」にて紹介したビデオコンテンツのスピーチ検索デモを簡略化して再利用しやすいものにしたものである。
demo site source code 主要テクノロジーと機能 Azure Media Indexer 2 Previewによる音声からテキスト抽出 このデモではAzure Media Indexer 2 Preview メディア プロセッサー (MP)を使用してビデオコンテンツからテキストを抽出している。このAzure Media Indexer 2 Previewは自然言語処理(NLP)や音声認識エンジンを駆使してビデオコンテンツより字幕用データ（時間やテキスト）や検索可能にするためのメタデータを抽出することができる。Indexer 2という名前の通り前のバージョンであるAzure Media Indexerが存在するが、これと比較すると、Azure Media Indexer 2 Previewは、インデックス作成が高速化され、より多くの言語をサポートしていることが特徴である。2016年11月6日時点で英語、スペイン語、フランス語、ドイツ語、イタリア語、中国語、ポルトガル語、アラビア語などがサポートされている（残念ながら日本語はまだ未サポート）。
下イメージはAzure Media Indexer 2 (Preview)で生成されるTTMLとWebVTTという代表的な字幕データフォーマット。
HTML5と字幕(Closed Caption) HTML5にはtrackタグエレメントを使ってビデオファイルに字幕を表示する機能が標準的に実装されている。本デモではHTML5に下記のように動画（Python_and_node.js_on_Visual_Studio.mp4）をVideoソースとしてtrackエレメントに字幕WebVttファイル（build2016breakout.vtt）を指定している。
&lt;video id="Video1" controls autoplay width="600"> &lt;source src="Python_and_node.js_on_Visual_Studio.mp4" srclang="en" type="video/mp4"> &lt;track id="trackJA" src="build2016breakout.vtt" kind="captions" srclang="ja" label="Closed Captions" default> &lt;/video> Azure Searchによる全文検索 デモページ上部にある検索窓にキーワードを入力してGoボタンを押すとビデオコンテンツの字幕データを全文検索してキーワードにマッチしたテキストとその表示時間に絞り込むことができる。ここでは全文検索エンジンにAzure Searchを使用し、Azure Media Indexer 2 (Preview)より抽出された字幕データを解析して字幕表示時間とその対応テキストを1ドキュメントレコードとしてAzure Searchにインジェストしてその生成されたインデックスに対してキーワードを元に全文検索することで実現している。字幕データ検索用のインデックススキーマは次のように字幕表示時間とその対応テキストをレコード単位となるように定義している。
{ "name": "stt", "fields": [ { "name":"id", "type":"Edm....</p></div><footer class=entry-footer>&lt;span title='2016-11-06 00:00:00 +0000 UTC'>November 6, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Speech-To-Text with Azure Media & Cognitive Services" href=https://yokawasa.github.io/posts/azure-media-cognitive-demos-video-ocr-speech-to-text/></a></article><article class=post-entry><header class=entry-header><h2>Making SSH lives in Azure easier with azuresshconfig</h2></header><div class=entry-content><p>UPDATED 2016-10-31: paramsオプション + Bash Completion追加
みんな大好きSSHとAzureのお話し。物理サーバ、EC2/仮想マシン、コンテナなどなんでもよいがその上にLinuxサーバをたてたらまずやることの1つにSSHログインのためにそのIPアドレス調べて~/.ssh/configにそのエントリーを追加してやることがあるんじゃないかと思います。この作業、エントリー数が少なければ大したことはないものの、追加対象のホストが大量にある場合はかなり面倒な作業になってきます。さらにDHCPなどでアドレスを動的に取得するような設定であればサーバの上げ下げのたびにIPアドレスが変わってくるので~/.ssh/configの更新が必要になってきて、どうしようもなく面倒になってきます。こういった単純でどうしようもなくつまらない作業は自動化したいですよね？ ここではそんな皆さんのためにazuresshconfigというツールを紹介させていただきます。
これは皆さんのAzureサブスクリプション下に作られた仮想マシン一覧（ARMに限る）の情報を取得して各仮想マシンごとのエントリー情報（マシン名とIPアドレス）を~/.ssh/configに追加・更新してくれるツール。新規に仮想マシンを追加した際や、仮想マシンのIPアドレスが追加した際にはazuresshconfigを実行してあげることで~/.ssh/configが最新のエントリー情報でアップデートされ、各マシンにマシン名でSSHログインできるようになります。
ちなみに、~/.ssh/configとは何ですか？という人はQiitaの記事「~/.ssh/configについて」がとても分かりやすく書かれているので参考になるかと。
インストール Pythonパッケージ管理ツールpipを使ってazuresshconfigをインストールしてください。インストール時に何かエラーが発生した場合は、こちらのページを参照いただき特に該当する事象がないか確認ください。
$ pip install azuresshconfig 設定ファイルの編集（サービスプリンシパル） $ vi $HOME/.azure/azuresshconfig.json { "subscription_id": "", "client_id": "", "client_scret": "", "tenant_id": "" } サービスプリンシパルを作る必要があります。サービスプリンシパルの作り方が分からない人、とってもよいドキュメントがあります。こちらを参照ください：「Use Azure CLI to create a service principal to access resources」
使い方 azuresshconfig --help usage: azuresshconfig.py [-h] [--version] [--init] [--profile PROFILE] [--user USER] [--identityfile IDENTITYFILE] [--private] [--resourcegroups RESOURCEGROUPS] [--params PARAMS] This program generates SSH config from Azure ARM VM inventry in subscription optional arguments: -h, --help show this help message and exit --version show program's version number and exit --init Create template client profile at $HOME/....</p></div><footer class=entry-footer>&lt;span title='2016-10-13 00:00:00 +0000 UTC'>October 13, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Making SSH lives in Azure easier with azuresshconfig" href=https://yokawasa.github.io/posts/azuresshconfig/></a></article><article class=post-entry><header class=entry-header><h2>embulk plugins for Microsoft Azure Services</h2></header><div class=entry-content><p>Here is a list of embulk plugins that you can leverage to transfer your data between Microsoft Azure Services and various other databases/storages/cloud services.
Plugin Name Target Azure Services Note embulk-output-azure_blob_storage Blob Storage Embulk output plugin that stores files onto Microsoft Azure Blob Storage embulk-input-azure_blob_storage Blob Storage Embulk input plugin that reads files stored on Microsoft Azure Blob Storage embulk-output-sqlserver SQL Databases, SQL DWH Embulk output plugin that Inserts or updates records to SQL server type of services like SQL DB/SQL DWH embulk-input-sqlserver SQL Databases, SQL DWH Embulk input plugin that selects records from SQL type of services like SQL DB/SQL DWH embulk-output-documentdb Comos DB Embulk output plugin that dumps records to Azure Cosmos DB embulk-output-azuresearch Azure Search Embulk output plugin that dumps records to Azure Search (as of Aug 30, 2016)...</p></div><footer class=entry-footer>&lt;span title='2016-09-01 00:00:00 +0000 UTC'>September 1, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to embulk plugins for Microsoft Azure Services" href=https://yokawasa.github.io/posts/embulk-plugins-for-microsoft-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>fluent-plugin-documentdb supports Partitioned collections</h2></header><div class=entry-content><p>I’d like to announce fluent-plugin-documentdb finally supports Azure DocumentDB Partitioned collections for higher storage and throughput. If you’re not familiar with fluent-plugin-documentdb, read my previous article before move on.
Partitioned collections is kick-ass feature that I had wanted to support in fluent-plugin-documentdb since the feature came out public (see the announcement). For big fan of fluent-plugin-documentdb, sorry for keeping you waiting for such a long time :-) If I may make excuses, I would say I haven’t had as much time on the project, and I had to do ruby client implementation of Partitioned collections by myself as there is no official DocumentDB Ruby SDK that supports it (As a result I’ve created tiny Ruby DocumentDB client libraries that support the feature....</p></div><footer class=entry-footer>&lt;span title='2016-08-20 00:00:00 +0000 UTC'>August 20, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to fluent-plugin-documentdb supports Partitioned collections" href=https://yokawasa.github.io/posts/fluent-plugin-documentdb-supports-partitioned-collections/></a></article><article class=post-entry><header class=entry-header><h2>Collecting logs into Azure DocumentDB using fluent-plugin-documentdb</h2></header><div class=entry-content><p>In this article, I’d like to introduces a solution to collect logs and store them into Azure DocumentDB using fluentd and its plugin, fluent-plugin-documentdb.
Azure DocumentDB is a managed NoSQL database service provided by Microsoft Azure. It’s schemaless, natively support JSON, very easy-to-use, very fast, highly reliable, and enables rapid deployment, you name it. Fluentd is an open source data collector, which lets you unify the data collection and consumption for a better use and understanding of data....</p></div><footer class=entry-footer>&lt;span title='2016-02-21 00:00:00 +0000 UTC'>February 21, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;5 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Collecting logs into Azure DocumentDB using fluent-plugin-documentdb" href=https://yokawasa.github.io/posts/collecting-logs-into-azure-documentdb-using-fluent-plugin-documentdb/></a></article><article class=post-entry><header class=entry-header><h2>fluentd plugins for Microsoft Azure Services</h2></header><div class=entry-content><p>UPDATED:
2016-12-10: Added fluent-plugin-azure-loganalytics to the list 2016-11-23: Added fluent-plugin-azurefunctions to the list Here is a list of fluentd plugins for Microsoft Azure Services.
Plugin Name Target Azure Services Note fluent-plugin-azurestorage Blob Storage Azure Storate output plugin buffers logs in local file and upload them to Azure Storage periodicall fluent-plugin-azureeventhubs Event Hubs Azure Event Hubs buffered output plugin for Fluentd. Currently it supports only HTTPS (not AMQP) fluent-plugin-azuretables Azure Tables Fluent plugin to add event record into Azure Tables Storage fluent-plugin-azuresearch Azure Search Fluent plugin to add event record into Azure Search fluent-plugin-documentdb Cosmos DB Fluent plugin to add event record into Azure Cosmos DB fluent-plugin-azurefunctions Azure Functions Azure Functions (HTTP Trigger) output plugin for Fluentd....</p></div><footer class=entry-footer>&lt;span title='2016-02-16 00:00:00 +0000 UTC'>February 16, 2016&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to fluentd plugins for Microsoft Azure Services" href=https://yokawasa.github.io/posts/fluentd-plugins-for-microsoft-azure-services/></a></article><article class=post-entry><header class=entry-header><h2>My patents</h2></header><div class=entry-content><p>I’ve just noticed that some of patents, which I was involved in for its publishing process, have been granted. Good news!
特開2011-065245 特開2011-065244 特開2011-065243 特開2011-060094 特開2011-060093 特開2008-287407</p></div><footer class=entry-footer>&lt;span title='2015-12-23 00:00:00 +0000 UTC'>December 23, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to My patents" href=https://yokawasa.github.io/posts/patents/></a></article><article class=post-entry><header class=entry-header><h2>ARMテンプレートを使って3分でAzure上にElasticsearchクラスタを構築する</h2></header><div class=entry-content><p>これはElasticsearch Advent Calendar 2015の17日目のエントリー
ARMテンプレートと呼ばれるデプロイ手法を使ってAzure上にElasticsearchクラスタをさくっと構築する方法についてのお話で、主にAzure界隈のElasticsearchユーザ向けの内容となっている。タイトルにある3分でというのは実際に計ったわけではないがそれくらい簡単且つ短時間でできることを強調したく使わせていただいている・・・ということを前もって補足しておく（汗）。
ARMテンプレートとは？ ARMテンプレートの前にARMについて少し解説する。ARMはAzure Resource Managerの略で、アプリケーション構築に必要な
リソース（ストレージ、ネットワーク、コンピュート/仮想マシンなど）をデプロイし管理するための仕組みである。どんなソリューションのデプロイにおいても少なからず仮想ネットワーク、仮想マシン、ストレージ、LBなどのインフラの構築が必要で旧来のやり方ではこれらを１つ１つデプロイしていたかと思う。一方ARMの世界では必要な構築要素をリソースという単位にして、これらリソースを個別にデプロイするのではなく全てのリソースをグループ化してまとめてデプロイし、それらを管理・監視することができる。そして、それら複数のリソースはJSON形式のテンプレートで表現・展開できるようになっていて、このテンプレートのことをARMテンプレートと呼ぶ。Infrastructure as Codeなんて言葉がはやっていたりするが、まさにそれをAzureで実現するための公式な仕組みがARMであり、ARMテンプレートなのである。
ちなみにこのARMテンプレート、手でいちから作る必要はなく、Azureクイックスタートテンプレートにさまざまなテンプレートが公開されているのでまずは自分の目的に似たようなことを実現しているテンプレートを選んでデプロイしてみることをお勧めする。完成されたものを見ることでお作法が学べるし、それをベースにカスタマイズしていくのが効率的である。
https://azure.microsoft.com/ja-jp/documentation/templates/ https://github.com/Azure/azure-quickstart-templates Elasticsearchクラスタのデプロイ 上記で説明したARMテンプレートを利用してElasticsearchクラスタのデプロイを行う。ここで使うARMテンプレートはAzureクイック・スタートテンプレートギャラリーにあるElasticsearchテンプレートを利用する。ARMテンプレートを使ったデプロイには複数の方法があるがここではLinux上でAzure CLIを使った方法で行う。ここでの実行OSはUbuntu 14.10。
最新版のAzure CLIをインストールしてからAzureサブスクリプションに接続する
$ sudo npm install -g azure-cli $ azure --version $ azure login 「Azure コマンド ライン インターフェイス (Azure CLI) からの Azure サブスクリプションへの接続」に書かれているように、Azure CLI バージョン 0.9.10 以降では、対話型の azure login コマンドを使用して、任意の ID でアカウントにログインできる。尚、バージョン 0.9.9 以降は、多要素認証をサポートしている。
デプロイ用のリソースグループを作成する
ここでは西日本（Japan West）リージョンにResource-ES-JapanWestという名前のリソースグループを作成する。
# azure group create -n "&lt;リソースグループ名>" -l "&lt;リージョン名>" $ azure group create -n "Resource-ES-JapanWest" -l "Japan West" ARMテンプレートのダウンロードとパラメータの編集...</p></div><footer class=entry-footer>&lt;span title='2015-12-17 00:00:00 +0000 UTC'>December 17, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to ARMテンプレートを使って3分でAzure上にElasticsearchクラスタを構築する" href=https://yokawasa.github.io/posts/deploy-elasticsearch-cluster-in-azure-using-arm-template/></a></article><article class=post-entry><header class=entry-header><h2>今一度Traffic Managerのエンドポイント監視について</h2></header><div class=entry-content><p>Azureが提供するDNSによるトラフィックルーティングサービスであるTraffic Managerについて、既にAzure利用ユーザに使い尽くされて新鮮味に欠けるサービスではあるものの、そのエンドポイント監視はTraffic Managerを扱う上でとても重要なことなので今一度そのルールについて整理したい。
Traffic managerの実態はエンドポイントの監視＋ルーティングを行うDNSサービスである。以下digの結果を見ていただいてわかる通りyoichika-demo1.trafficmanager.netという外向きの名前に対してこの時点ではwebappdemo3.cloudapp.netがCNAMEされている。Traffic Managerは利用ユーザが設定したエンドポイントを監視し、その結果に応じて適切なルーティングを行う。ルーティング方法にはフェールオーバー、ラウンドロビン、パフォーマンスの3通りがある。これについて詳しくは「Traffic Managerのルーティング方法」を参照いただきたい。
; &lt;&lt;>> DiG 9.9.5-4.3ubuntu0.1-Ubuntu &lt;&lt;>> yoichika-demo1.trafficmanager.net +noall +answer ;; global options: +cmd yoichika-demo1.trafficmanager.net. 30 IN CNAME webappdemo3.cloudapp.net. webappdemo3.cloudapp.net. 60 IN A 70.37.93.167 次に肝心のエンドポイントの監視について「Traffic Manager の監視について」の監視シーケンスを使って要点を整理する。
エンドポイントへのProbe送信(ハートビート)は30ごとに実行 ProbeはHTTP 200 OKかどうかで判定 4回連続して失敗が続いた後、監視システムは使用不可のクラウドサービスを使用不可とみなしそのエンドポイントにトラフィックのルーティングを行わない(④にあたる。⑥は後述) DNS の有効期限 (TTL) によりDNSリゾルバーで解決された名前がDNS サーバー上でキャッシュされている期間使用できないサービスの DNS 情報を引き続き配信してしまう⇒トラフィック減少期間 (⑥にあたる)。DNSのTTLの既定値は、300秒(5分) つまり、エンドポイントがダウンした場合、Probeにより使用不可とみなすのに最大120秒(30秒 x 4)、さらにDNSのTTLの期間（既定値は300秒）を加えると、完全に問題のあったエンドポイントへのトラフィックが停止するまでに標準的に420秒、約7分は見ておく必要があるということになる。当然ながらこの7分間トラフィックがロスする可能性があるため、俊敏なフェールオーバーを期待する場合は別の仕掛けを用意する必要がある。ご注意ください。</p></div><footer class=entry-footer>&lt;span title='2015-11-29 00:00:00 +0000 UTC'>November 29, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to 今一度Traffic Managerのエンドポイント監視について" href=https://yokawasa.github.io/posts/traffic-manager-endpoint-monitoring/></a></article><article class=post-entry><header class=entry-header><h2>Static linking DLL to EXE in C Sharp</h2></header><div class=entry-content><p>Q1. C Sharpでexeに複数DLLをスタティックリンクさせて１ファイルにすることはできますか？
C、C++ではおなじみのスタティックリンクだが、そもそもC Sharpではスタティックリンクができない。ただし
MS Research謹製のILMergeを使えば実行ファイル(exe)に対して複数のクラスアセンブリ(DLL)を１つのアセンブリにマージすることはできる。使い方はこちらが参考になる。また、ILMerge-GUIというGUIツールもある。
Q2. Visual Studioのビルドでも自動的に複数ファイルを１つにまとめることはできますか？
パッケージマネージャーでILMerge.MSBuild.Tasksをインストールして*.csprojファイルに自動アセンブリ生成するための設定を追記するとVSのビルドで複数ファイルが１つのアセンブリにマージされたファイルが自動的にできあがる。参考: StackOverflow 「How to Integrate ILMerge into Visual Studio Build Process to Merge Assemblies?」
ILMerge.MSBuild.Tasksをインストール Install-Package ILMerge.MSBuild.Tasks *.csprojファイルに下記設定を追記 &lt;!-- Code to merge the assemblies into one --> &lt;UsingTask TaskName="ILMerge.MSBuild.Tasks.ILMerge" AssemblyFile="$(SolutionDir)\packages\ILMerge.MSBuild.Tasks.1.0.0.3\tools\ILMerge.MSBuild.Tasks.dll" /> &lt;Target Name="AfterBuild"> &lt;ItemGroup> &lt;MergeAsm Include="$(OutputPath)$(TargetFileName)" /> &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名1" /> &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名2" /> ... &lt;MergeAsm Include="$(OutputPath)追加するDLLファイル名N" /> &lt;/ItemGroup> &lt;PropertyGroup> &lt;MergedAssembly>出力する結果アセンブリファイル名（フルパス）&lt;/MergedAssembly> &lt;/PropertyGroup> &lt;Message Text="ILMerge @(MergeAsm) -&amp;gt; $(MergedAssembly)" Importance="high" /> &lt;ILMerge InputAssemblies="@(MergeAsm)" OutputFile="$(MergedAssembly)" TargetKind="SameAsPrimaryAssembly" /> &lt;/Target> &lt;/Project> VSビルド実行で、マージされたファイルが生成（*....</p></div><footer class=entry-footer>&lt;span title='2015-09-09 00:00:00 +0000 UTC'>September 9, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Static linking DLL to EXE in C Sharp" href=https://yokawasa.github.io/posts/tips-visual-studio-csharp-merge-exe-and-dll/></a></article><article class=post-entry><header class=entry-header><h2>SOCKSプロキシを経由したAzure VNETプライベートリソースへのアクセス</h2></header><div class=entry-content><p>UPDATED 2017-03-22: Added SOCKS Proxy Configuration for Internet Explorer
外部からの接続（SSH、HTTPなど）を受け付けていないAzure 仮想ネットワーク(以下VNET)内のリソースにSOCKSプロキシを経由して外部からアクセスしましょうというお話。本記事ではAzure VNET内の外部からのアクセス許可していないVMへのSSHログインとHTTPサーバコンテンツへのブラウジングの2つの方法を紹介する。
SOCKS(RFC1928) とはさまざまなアプリケーションが間にファイアーウォールを挟んでいても安全に快適にやり取りができるようにすることを目的として作られたプロトコルのことで、SOCKSプロキシはSOCKSプロトコルを受け取りファイアウォール内外との接続を可能にするものである。エンドポイントやNetwork Security Group (NSG)によりネットーワーク分離設定されたAzure VNET内のリソースに対して一時的に本来直接アクセス許可しないネットワークからアクセスが必要な状況はあるかと思う。そのような時に毎回設定変更で必要なプロトコル、アクセス先に対して穴をあけるのは非常に面倒であり、またサイト間VPN、ポイント対サイトVPNとなるとさらに手間がかかる。お手軽に、もしくは定常的ではないが一時的に内部リソースにアクセスしたい場合にSOCKSプロキシ経由でのアクセスを検討してみてはいかがだろうか。以下はSOCKSプロキシ経由によるAzure VNET内のプライベートリソースへのアクセスイメージである。
SOCKSプロキシの作成 まずはOpenSSHのダイナミックポートフォワード機能を使ってSOCKSプロキシを作成する。ダイナミックポートフォワードはSSHをSOCKSプロキシとして振舞うことを可能にする。SSHでアクセス先ホストと DynamicFoward(-D)でポートを指定することでlocalhostにSOCKSプロキシが立ち上がり指定のTCPポート(SOCKSプロキシサーバは基本的は1080だが、割り当て可能なポートであればどのポートでもOK)をlocalhost側からログイン先ホストのSSHサーバに転送することができるようになる。もちろん経路は暗号化される。現状のサポートプロトコルはSOCKS4とSOCKS5。
例えば上図でいうとJump Server(踏み台)にDynamicFoward(-D)1080でログインすると、Jump Serverにポート1080を転送するSOCKSプロキシが localhostに立ち上がり、そのlocalhost:1080に対してSOCKS4またはSOCKS5プロトコルで接続することでJump Serverを経由して通信を行うことができるようになる。
localhostポート1080のJump Serverへのダイナミックフォワードは次のように-Dオプションで行う。
$ ssh -2 -D 1080 -l [Account] [Jump Server] 毎回-Dオプション指定が面倒な場合は、次のようにconfg(ssh_config)にDynamicForwardの記述することも可能。
~/.ssh/config
Host JumpServer User [Account名] HostName/IP [Jump Serverホスト/IPアドレス] Protocol 2 ForwardAgent yes DynamicForward 1080 上記OpenSSHの設定は、Linux/Macの場合は標準Terminalを使えばよいが、Windowsの場合はCygwin、XmingなどX端末エミュレータソフトをインストールしていただく必要がある。またX端末エミュレーターをインストールしなくともWindowsでは有名なSSHクライアントソフトPuttyがダイナミックポートフォワードに対応しているためPuttyを使ってSOCKSプロキシ作成することも可能。詳しくは「Dynamic Port Forwarding with SOCKS over SSH」が参考になるかと。
SOCKSプロキシを使ったSSH接続 次に上記で作成したSOCKSプロキシを経由してVNET内のサーバにSSH接続をする。 netcatでSOCKSプロキシを経由してlocalhostから目的のVNET内サーバ（ServerX）間にnetcatトンネルを作成してServerXにはそのnetcatトンネルを通じて接続する。
local$ ssh -2 -l [Account] -o 'ProxyCommand nc -x localhost:1080 %h %p' [ServerX] netcat のプロキシ指定は-xオプションで行う。 ここでは事前に作成したSOCKSプロキシ(localhost:1080)を指定。 netcatトンネルの作成コマンドはProxyCommandに記述する。こちらも毎回長いオプション入力を避けるために config（ssh_config）設定すると便利である。...</p></div><footer class=entry-footer>&lt;span title='2015-08-18 00:00:00 +0000 UTC'>August 18, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to SOCKSプロキシを経由したAzure VNETプライベートリソースへのアクセス" href=https://yokawasa.github.io/posts/accessing-private-resource-in-azure-vnet-via-socks-proxy/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://yokawasa.github.io/posts/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://yokawasa.github.io/posts/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://yokawasa.github.io/>unofficialism</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>