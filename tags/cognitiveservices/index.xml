<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CognitiveServices on unofficialism</title>
    <link>https://yokawasa.github.io/tags/cognitiveservices/</link>
    <description>Recent content in CognitiveServices on unofficialism</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 18 Dec 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://yokawasa.github.io/tags/cognitiveservices/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Detecting faces in Video contents using Azure Cognitive Services Face API</title>
      <link>https://yokawasa.github.io/posts/azure-media-cognitive-demos-video-frames-face-recognition/</link>
      <pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://yokawasa.github.io/posts/azure-media-cognitive-demos-video-frames-face-recognition/</guid>
      <description>過去に本ブログでビデオコンテンツを切り口とした音声認識やOCR技術を利用したデモを紹介したが、ここではビデオコンテンツの中の人物出現箇所に連動して人物名を字幕で表示させるデモとその実装方法を紹介したい。人物識別にはAzureのCognitive ServicesのFace APIを使っていて、これで動画の中に出現する顔の検出を行い、予め登録している人物リストとのマッチングにより実現している。 Cognitive Serivcesとは視覚、音声、言語、知識などマイクロソフトがこれまで研究を通じて開発してきたさまざまな要素技術をAPIとして提供しているサービスのことで、最近巷で人工知能（AI）だとかインテリジェンスとかいうキーワードをよく耳にするのではないかと思うがAzure利用シナリオでそういったインテリジェンス（知能/知性）を兼ね備えたアプリを作る場合は間違いなく中核となるサービスの1つである。Face APIはその中でも顔の検出・識別や、顔にまつわる感情、特徴などメタデータ抽出に特化したAPIである。
demo site source code 主要テクノロジーと機能 下図は今回のデモ作成のために行っている処理フローと主要テクノロジーを表している。やっていることは大きく分けて3つ: (1) 動画コンテンツをAzure Media Encoder Standardを使ってフレームごとの静止画像の作成, (2) Cognitive ServicesのFace APIを使って1より得られた静止画像から顔の検出を行い予め登録している人物リストとマッチング（最も類似度が高いものを本人とみなす）して人物を識別, (3) 2で得られた各フレーム中の人物情報を時間順に並べて字幕(Closed Caption)用のデータファイルを生成。以下、各処理の詳細について説明する。
1. Azure Media Encoder Standardでフレームごとの静止画生成 残念ながらFace APIはビデオコンテンツから直接顔検出することができないため、一旦ビデオコンテンツから各フレームごとの静止画を生成してその静止画を対象に処理を行う必要がある。ここでは各フレームごとの静止画生成にAzure Media Encoder Standard（MES）を利用する。MESを使うことでエンコードタスクとしてビデオコンテンツに対して様々な処理を行うことができるのだが、MESにはそのエンコードタスクの１つとしてサムネイル生成のためのタスクが用意されており、今回はこのサムネール生成タスクを利用する。他のエンコードタスク同様にサムネイル生成タスクについてもプリセットと呼ばれるエンコードに必要な情報を記述した XML または JSON形式ファイルを用意する必要がある。今回は1秒フレームごとにJPEG形式の静止画（サムネイル）を生成するために次のようなプリセット（amsmp-thumbnail-config.json）を用意した。
{ &amp;#34;Version&amp;#34;: 1.0, &amp;#34;Codecs&amp;#34;: [ { &amp;#34;Start&amp;#34;: &amp;#34;00:00:00&amp;#34;, &amp;#34;Step&amp;#34;: &amp;#34;00:00:01&amp;#34;, &amp;#34;Type&amp;#34;: &amp;#34;JpgImage&amp;#34;, &amp;#34;JpgLayers&amp;#34;: [ { &amp;#34;Quality&amp;#34;: 90, &amp;#34;Type&amp;#34;: &amp;#34;JpgLayer&amp;#34;, &amp;#34;Width&amp;#34;: 640, &amp;#34;Height&amp;#34;: 360 } ] } ], &amp;#34;Outputs&amp;#34;: [ { &amp;#34;FileName&amp;#34;: &amp;#34;{Basename}_{Index}{Extension}&amp;#34;, &amp;#34;Format&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;JpgFormat&amp;#34; } } ] } MESによるサムネイル処理実行方法やプリセットの詳細については「Media Encoder Standard を使用した高度なエンコード」や同ページの「サムネイルを生成する」項を参照ください。尚、今回のサムネイル生成のためのエンコーディング処理は小生自作の「azure-media-processor-java」を利用してバッチ実行している。</description>
    </item>
    
  </channel>
</rss>
