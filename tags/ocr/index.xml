<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>OCR on Yoichi Kawasaki</title>
    <link>https://unofficialism.info/tags/ocr/</link>
    <description>Recent content in OCR on Yoichi Kawasaki</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 07 Nov 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://unofficialism.info/tags/ocr/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Video OCR using Azure Media &amp; Cognitive</title>
      <link>https://unofficialism.info/posts/azure-media-cognitive-demos-video-ocr/</link>
      <pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://unofficialism.info/posts/azure-media-cognitive-demos-video-ocr/</guid>
      <description>OCRとはOptical Character Recognitionの略で日本語にすると光学文字認識と訳されており、ざっくりと画像の中の文字をテキストに変換する技術のことを指す。テキストに変換されるということは勘が鋭い皆さんはお気づきだと思うが、テキストの全文検索であったり、テキストから音声への変換、さらには機械翻訳を使って多言語への変換といった展開が考えられる。そんな可能性を秘めたOCRであるが、ここではそのOCRの技術を使ってビデオファイルから抽出したテキストデータを元にビデオに字幕表示したり、動画中に表示される文字を全文検索をするデモを紹介したい。内容的には「Azure Media &amp;amp; Cognitiveデモ:Speech-To-Text」で紹介したデモのOCR版といったところ。
demo site source code 主要テクノロジーと機能 Azure Media OCRメディアプロセッサによるテキスト抽出 このデモではAzure Media OCRメディアプロセッサー(MP)を使用してビデオファイル内のテキストコンテンツを検出してテキストファイルを生成している。OCRメディアプロセッサーは入力パラメータによりビデオ解析の挙動を調整することができる。主なパラメータとしては検索対象テキストの言語（日本語もサポート）、テキストの向き、サンプリングレート、ビデオフレーム内のテキスト検出対象のリージョンがあるが、本デモでの入力パラメータ（Video-OCR-Search-Python/src/ocr-detectregion.json）は以下の通り検索対象言語は日本語、1秒おきのサンプリングレート、テキスト検出対象のリージョンからビデオフレーム内の上部1/4を省く設定（検出対象をフレームトップから85 pixel以下を対象）にしている。
{ &amp;#34;Version&amp;#34;:&amp;#34;1.0&amp;#34;, &amp;#34;Options&amp;#34;: { &amp;#34;Language&amp;#34;:&amp;#34;Japanese&amp;#34;, &amp;#34;TimeInterval&amp;#34;:&amp;#34;00:00:01.000&amp;#34;, &amp;#34;DetectRegions&amp;#34;: [ {&amp;#34;Left&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;Top&amp;#34;:&amp;#34;85&amp;#34;,&amp;#34;Width&amp;#34;:&amp;#34;1280&amp;#34;,&amp;#34;Height&amp;#34;:&amp;#34;635&amp;#34;} ] } } そして、Azure Media OCRメディアプロセッサはビデオで検出された文字を下記のような表示時間に基づいてセグメント化された形で結果出力する。結果ファイルの完全版はこちら（azuresubs.json）を参照ください。
{ &amp;#34;fragments&amp;#34;: [ { &amp;#34;start&amp;#34;: 0 &amp;#34;interval&amp;#34;: 319319, &amp;#34;duration&amp;#34;: 319319, &amp;#34;events&amp;#34;: [ [ { &amp;#34;language&amp;#34;: &amp;#34;Japanese&amp;#34;, &amp;#34;text&amp;#34;: &amp;#34;Azure の 契 約 内 容 を 変 更 す る Microsoft Azure&amp;#34; } ] ] }, { /* fragment1 */ }, { /* fragment2 */ }, .</description>
    </item>
    
  </channel>
</rss>
