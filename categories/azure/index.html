<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Azure | Yoichi Kawasaki</title><meta name=keywords content><meta name=description content="Yoichi Kawasaki yokawasa.github.io"><meta name=author content="Yoichi Kawasaki"><link rel=canonical href=https://unofficialism.info/categories/azure/><link crossorigin=anonymous href=https://unofficialism.info/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><link rel=icon href=https://unofficialism.info/Thinking_Face_Emoji_large.png><link rel=icon type=image/png sizes=16x16 href=https://unofficialism.info/Thinking_Face_Emoji_large.png><link rel=icon type=image/png sizes=32x32 href=https://unofficialism.info/Thinking_Face_Emoji_large.png><link rel=apple-touch-icon href=https://unofficialism.info/Thinking_Face_Emoji_large.png><link rel=mask-icon href=https://unofficialism.info/Thinking_Face_Emoji_large.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://unofficialism.info/categories/azure/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Azure"><meta property="og:description" content="Yoichi Kawasaki yokawasa.github.io"><meta property="og:type" content="website"><meta property="og:url" content="https://unofficialism.info/categories/azure/"><meta property="og:image" content="https://unofficialism.info/profile.jpg"><meta property="og:site_name" content="Yoichi Kawasaki"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://unofficialism.info/profile.jpg"><meta name=twitter:title content="Azure"><meta name=twitter:description content="Yoichi Kawasaki yokawasa.github.io"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://unofficialism.info accesskey=h title="unofficialism (Alt + H)">unofficialism</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://unofficialism.info/posts title=posts><span>posts</span></a></li><li><a href=https://unofficialism.info/works title=works><span>works</span></a></li><li><a href=https://unofficialism.info/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://unofficialism.info/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://unofficialism.info>Home</a>&nbsp;»&nbsp;<a href=https://unofficialism.info/categories/>Categories</a></div><h1>Azure</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>Kubernetes x PaaS コンテナアプリケーションのNoOpsへの挑戦 (Japan Container Days v18.04)</h2></header><section class=entry-content><p>先日、4月19日に開催されたJapan Container Days v18.04にて「Kubernetes x PaaS – コンテナアプリケーションのNoOpsへの挑戦」というタイトルでセッションを担当させていただいた。その名の通りメインがKubernetesで、KubernetesアプリケーションにおいてNoOps（運用レス）を目指すためのにどういった工夫ができるのか、どういったものを活用していけばよいのか、という内容です。このブログではJapan Container Daysでの発表に使用したスライドの共有とセッションに中のサンプルやデモについて補足させていただく。
Session Slides Kubernetes x PaaS – コンテナアプリケーションの NoOpsへの挑戦 from Yoichi Kawasaki
補足情報 1. Open Service Broker for AzureでAzure Database for MySQLの利用 スライドでお見せした実際のファイルを使ってAzure Database for MySQLのサービスインスタンス作成、バインディング、そして実際のアプリケーションからの利用までの流れを紹介させていただく。
Open Service Broker for AzureプロジェクトのGithubにあるサンプルファイルmysql-instance.yamlとmysql-binding.yamlを使ってそれぞれServiceInstanceとServiceBindingを作成する `
# Provisioning the database, basic50 plan ... $ kubectl create -f mysql-instance.yaml # Wait until ServiceInstance named example-mysql-instance get ready 'Status => Ready', # then execute the following to create a binding for this new database, $ kubectl create -f mysql-binding....</p></section><footer class=entry-footer><span title='2018-04-25 00:00:00 +0000 UTC'>April 25, 2018</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Kubernetes x PaaS コンテナアプリケーションのNoOpsへの挑戦 (Japan Container Days v18.04)" href=https://unofficialism.info/posts/kubernetes-x-paas-noops-container-days-201804/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Controlling Azure Media Services traffic with Traffic Manager</h2></header><section class=entry-content><p>This is an article on how you can achieve Azure Media Services (AMS) streaming traffic distribution with Traffic Manager.
The process for a client to find target AMS streaming endpoints The figure shows how a client find target AMS streaming endpoints with Traffic Manager and requests from video players are distributed to streaming endpoints in AMS:
When AMS endpoints are added to an Azure Traffic Manager profile, Azure Traffic Manager keeps track of the status of the endpoints (running, stopped, or deleted) so that it can decide which of those endpoints should receive traffic....</p></section><footer class=entry-footer><span title='2018-01-06 00:00:00 +0000 UTC'>January 6, 2018</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Controlling Azure Media Services traffic with Traffic Manager" href=https://unofficialism.info/posts/controlling-azure-media-services-traffic-with-traffic-manager/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>15分でお届けするElastic Stack on Azure設計・構築ノウハウ</h2></header><section class=entry-content><p>UPDATED on Feb 3, 2018 - Elastic社イベントサイトを追加
イベント開催日から少々時間が経過したが、Elastic {ON} Tour 2017 東京（2017年12月14日開催）というElastic社オフィシャルのユーザーカンファレンスにて登壇させていただく機会があり、そこで「15分でお届けする Elastic Stack on Azure 設計・構築ノウハウ」というお題でお話をさせていただいた。個人的にとても大好きなプロダクトなので、そのユーザーカンファレンスでお話をさせていただいたということと、そのプロダクトのAzureでの利用促進に微力ながらも貢献できたということは光栄至極である。ここではそのElastic {ON} Tourでの発表で使用したスライドに補足解説を加えて共有させていただく。
セッションスライド（＋デモ動画） 15分でお届けする Elastic Stack on Azure 設計・構築ノウハウ from Yoichi Kawasaki
補足解説 デプロイメント AzureでのElastic Stackの利用は当然ながら仮想マシン（VM）を並べてそこにクラスタを構築することになる。残念ながら現時点でマネージドのElasticサービスはAzureには存在しない。VMベースということで特にオンプレと変わらずマニュアルであったり、ChefやAnsibleなどの構成管理ツールを使ってクラスタを組んだり柔軟な構築が可能であるものの、ここではAzureでの構築ということでARMテンプレートを使ったデプロイメントの方法を紹介している。
Azure Marketplaceからのデプロイ：最も手っ取り早い方法。30日のX-Packトライアルライセンスが付いていて、トライアル期間が過ぎてもBYOLでライセンスの更新が可能。テンプレートでは2017年12月時点でv2.0.2 〜 v5.6.3の選択が可能。何も考えず最新版をご利用ください。 Github上のARMテンプレートをカスタマイズしてデプロイ：Elastic社が用意したGithub上のARMテンプレートがあるのでそれを自分の要件に応じてカスタマイズしてデプロイメントをする。Azure CLIやPowerShellなどコマンドを使ったデプロイメントが可能なので構成管理ツールに組み込んで周辺環境を合わせて自動構築設定も可能。慣れてきたらこちらがよいでしょう。 推奨仮想ハードウェアとDISK Elasticクラスタ全体のパフォーマンスを引き出すためには機能別に適正なVMインスタンスとサイズを選択ください。またVMにアタッチするディスクについてはビルトインで可用性設定がされているManaged Disk、もしくはPremium Managed Diskを選択することをお忘れなく。
可用性の設定について AzureでIaaSで可用性の設定といえばおなじみの可用性セット（Availability Set）と可用性ゾーン（Availability Zone）。当然Elastic Stackのクラスタを組む時もこれらの設定を入れましょうというお話。可用性ゾーンは、その可用性レベルの高さから将来的には可用性ゾーンが主流な設定になっていくはずであるものの、2017年12月時点でPreviewリリースであり、利用可能リージョンが米国東部第２、西ヨーロッパのみというとても限定的なものとなっている。現時点でプロダクション用途となると可用性セット一択なので何も考えずに可用性セットを組んでください。
可用性セット（Availability Set）
一つのDCの中で同一の物理ラックや電源などを配置しないようにして、障害が発生してもグループの中のどこかのVMは生きているようにする設定のこと VM SLA 99.95%で提供 可用性ゾーン（Availability Zone）
各VMを別々のゾーンに配置するのでDCレベルの障害につよい（それぞれゾーンは電源、ネットワーク、冷却装置が完全に物理的に分離されたものとなっている）。ちなみに、Azureのリージョンは複数のデータセンターで構成されており、その間を高速なバックボーンで接続して1つのリージョンとして透過的に利用が可能となっているのでこのようなことができるわけだ VM SLA 99.99%で提供 【注意点】可用性ゾーンの設定ではDCが分かれて配置されるので次の２点の考慮が必要：（１）マスターは各ゾーンに分散するように各ゾーン最低１ノード配置すること（２）データノードはゾーンにまたがる通信が極力起こらないように工夫すること。これを実現するのがShard Allocation Awarenessという仕組みで、この仕組みをつかうことで 同一ゾーン内に配置されているノードだけで完全なシャードを保持するようにして、検索要求が同一ゾーン内で完結できるように設定が可能となる ネットワークセキュリティグループの設定 AzureのIaaSにおけるネットワークフィルタリングの設定に、ネットワークセキュリティグループ（NSG）とよばれるL4フィルタリングがある。当然ながら、既にX-Packを導入していればそのセキュリティ機能の１つとしてネットワークレベルのアクセス制御についても行うことができるが、X-Packを導入していない場合は確実にNSGの設定は必要になってくる。また、Elastic Stack以外のアプリケーションとの連携の際にも必ず必要になってくる。Azure上でのシステム構築では欠かすことのできない設定の１つ。
Azureサービスからのデータコレクション Azure VMについては、オンプレ同様に、ビルトインのBeatsやlogstashとの連携により、そのログやMetricsなどのデータコレクションを実現することができる。一方、Azureが特に力を入れているPaaS（Platform as a Services）からのデータコレクションについてはどうかというと、下記のサービスについては既にビルトインで用意されている機能や、コミュニティ製Logstash Input プラグインを利用することでデータコレクションを実現することができる。 H2M_LI_HEADER Azure Blob Storage: logstash-input-azureblob H2M_LI_HEADER Azure Service Bus (Topic): logstash-input-azuretopic H2M_LI_HEADER Azure Event Hub: logstash-input-azureeventhub H2M_LI_HEADER Azure SQL Database: logstash-input-jdbc H2M_LI_HEADER Azure Database for MySQL: logstash-input-jdbc H2M_LI_HEADER Azure Database for PostgreSQL: logstash-input-jdbc H2M_LI_HEADER Azure HDInsight: ES-Hadoopによる連携...</p></section><footer class=entry-footer><span title='2018-01-01 00:00:00 +0000 UTC'>January 1, 2018</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to 15分でお届けするElastic Stack on Azure設計・構築ノウハウ" href=https://unofficialism.info/posts/15min-elastic-stack-on-azure/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Azure Functions Python Programming - Experimental</h2></header><section class=entry-content><p>今年もあと少し。ほぼ趣味の範囲を超えないレベルで今年取り組んだテーマの１つにAzure Functions with Pythonがある。あまり情報が無い中、興味本位でサンプルコードを作っては動かして試して得られた情報をシコシコとGithubに上げているうちにナレッジが溜まって来た。それほど多くはないと思うがPythonでAzure Functionsアプリを作りたいという人もいると思うのでノウハウをブログにまとめておく。いきなり水を差すようではあるが、現時点（2017年12月）ではAzure FunctionsのPythonサポータビリティはExperimental（実験的サポート）でありプロダクション向きではない状況であるので、ホントにPythonが好きな人がOn your own riskで楽しんでいただければと思う。
Azure FunctionsのPythonサポート状況 Azure FunctionsのRuntimeには大きく1系と２系の２種類あるが、現時点でPythonは1系でのみExperimentalサポートという状況（ See also 言語サポート状況）
Experimental（実験的サポート）なので本番での利用は非推奨であり、公式サポートはない（ベストエフォートでのサポートは得られるはず）。また、当然ながらGA言語に比べパフォーマンスは悪い。PythonはFunction呼び出し毎にpython.exeが実行される（GA言語はRuntimeと同じプロセスで実行）。
将来的な話をすると、Azure Functions Runtime 1系でのPythonサポートについては今のExperimentalの域を超えることはないだろう。一方、Runtime 2系ではPythonが正式サポートされるように対応が進められている。ただし時期は未定。この対応については下記Github Issueが切られており、ある程度の対応状況であれば確認可能。Pythonを使う利点の１つに、強力な数理計算、自然言語解析、機械学習系モジュールがあるが、早く安定とパフォーマンスが備わったPythonサーバレスアプリ実行環境でこれら強力なモジュールを活用できたらと思うのは私だけではないだろう。今後の進展に期待。
Feature planning: first class Python support Hosting Planの選択について Consumption Plan vs App Service Plan Azure FunctionsのHosting PlanにはConsumption PlanとApp Service Planの2つがあって、言語に関係なく各プランの特徴は次の通り:
Consumption Plan
コード実行時にコンピューティング割り当て リソース使用量（関数実行時間、使用メモリ）で課金 自動スケール、各処理は〜10分まで App Service Plan
専用VMでリソース確保 継続処理：10分以上の処理 App Service環境でのみ可能な処理: App Service Environment, VNET/VPN接続, より大きなサイズのVM, etc Pythonで使う上で気をつけるポイント Python 3.XなどRuntimeの変更を行う場合は、専用環境である必要があってApp Service Plan必須 Consumption Planの場合、Pythonに限らずColdスタート問題という休眠したFunctionの起動が極端に遅くなる問題があるのだが、Pythonの場合は、GA言語に比べてパフォーマンスが悪く、SciPyなど重めのモジュールを利用すると絶望的に遅くなることからConsumption Planでの問題が特に顕著にでてくる。これまでの経験から、小さいインスタンスを並べるConsumption Planよりも比較的大きなサイズのVMが選べるApp Service Planの方が向いていることが多い。Pythonの場合は、予測可能なワークロードに対してApp Service Planで使うほうが問題が少ない。Consumption Planの魅力であるMicro Billing（使った分だけ課金）やリクエストに応じたオートスケーリングといった真のサーバレスに期待される要件は既に正式サポートしているC#、Nodeでやっていただくのがよいかと。 [参考] Coldスタート問題 Consumption Planにおける問題 Azure Functions Cold Start Workaround The only downside is that the consumption model that keeps the cost so dirt-cheap means that unless you are using your Function constantly (in which case, you might be better off with the non-consumption options anyway), you will often be hit with a long delay as your Function wakes up from hibernation 休眠したFunctionをどう起こすかがポイント。事前に空リクエストを送ることが考えられるが問題はタイミング（フォーム開いた時とか） Python 3....</p></section><footer class=entry-footer><span title='2017-12-29 00:00:00 +0000 UTC'>December 29, 2017</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Azure Functions Python Programming  - Experimental" href=https://unofficialism.info/posts/azure-functions-app-development-with-python-experimental/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Developing Full Managed Search Application in Azure</h2></header><section class=entry-content><p>これは9/29 Azure Web Seminar 「Azure サービスを活用して作るフルマネージドな全文検索アプリケーション」のフォローアップ記事です。なかなか暇ができず少々時間が経過してしまいました。
Azure サービスを活用して作るフルマネージドな全文検索アプリケーション from Yoichi Kawasaki
Sample Application & Source Code セミナーで紹介したサンプルアプリはAzure公式サイトに載せてある代表的なサービスのFAQデータを元にしたHTML/CSS/JavascriptによるQ＆Aナレジッジベース検索のシングルページアプリケーションです。検索エンジンにAzure Searchを使い、データソースにCosmos DBを使いAzure SearchのCosmosDB Indexerでクローリングする構成にしてます。ソースコードと設定手順は以下Githubプロジェクトにアップしてあります。もしバグや設定手順等でご質問があればGithubでIssue登録いただければ時間を見つけて対応させていただきます。
Source Code: https://github.com/yokawasa/azure-search-qna-demo/
Demo: AI Digital Media Search セミナー中に紹介した非構造化データの全文検索デモとして紹介したAI Digital Media Searchアプリケーション。メディア x 音声認識 x 機械翻訳 x 全文検索全てを絡めた面白いアプリケーションなのでこちらでデモ動画とソースコードを共有します。またこのアプリはAzure PaaSサービスを組み合わせてプレゼンテーションレイヤー(Web App for Container)のみならずデータ生成部分（AMS, Functions, Logic App）も全てサーバレスで実現しているのでこのエリアのサンプルアプリとしてもとても良いものになっていると思います。
Demo Video: AI Digital Media Search Demo Source Code: https://github.com/shigeyf/ai-digitalmedia AzureSearch.js - Azure Search UIライブラリ AzureSearch.jsはAzure SearchのUIライブラリで、Azure Searchプロダクトチーム主要開発者により開始されたOSSライブラリです。TypeScriptで書かれているのでとても読みやすく、また、ライブラリが提供するオブジェクト操作により非常に短いコードでサーチボックス、結果出力、ページネーション、ファセット、サジェスションなどで構成されるサーチ用UIを簡単に組み立てることが可能です。なかなかいけているライブラリにもかかわらず、あまり世の中に知られていないのはもったいないと思いセミナーの最後で紹介させていただきました。これ使わない手はないです。手っ取り早くは、下記のAzureSearch.jsアプリテンプレートジェネレータページで皆さんのAzure SearchアカウントのQueryKeyとインデックススキーマ（JSONフォーマット）を入力するとAzureSearch.jsアプリの雛形が生成されますので、そこから始めるのがよいかと思います。
AzureSearch.jsプロジェクトトップ＠Github デモアプリサイト AzureSearch.jsアプリのテンプレートジェネレータ END</p></section><footer class=entry-footer><span title='2017-10-22 00:00:00 +0000 UTC'>October 22, 2017</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Developing Full Managed Search Application in Azure" href=https://unofficialism.info/posts/building-full-text-search-application-using-azure-services/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Azure Search Text Analyzer Tools - azure-search-ta</h2></header><section class=entry-content><p>Azure Searchのアナライザーによるテキスト解析結果を出力する（だけの）ツールを作ってみたのでここで紹介します。その名もazure-search-ta（ta=Test Analyzer）。中身はAzure SearchのAnalyzer APIの出力結果を整形して表示させていているだけの単純なものでありますが、Azure Searchの全文検索チューニングやキーワードにヒットしない原因調査をする際には役に立つと思ってます。「どうしてこのキーワードがひっかからないの？」を突き詰めるには最終的にアナライザのテキスト解析結果と突き合わせる必要があるのと、アナライザーを選択する際にテキスト解析が視覚化されていると判断しやすいだろうと。ツールは2種類で （１）Web UIツールと（２）コマンドラインツール
Web UI Tool https://github.com/yokawasa/azure-search-ta
インストールは超簡単。（１）Githubからazure-search-taをclone （２）azure-search-ta/ui 配下のファイルをPHPが動くWebサーバにコピー （３）analyze-api.phpをエディタで開いてお使いのAzure Searchカウント名とAzure Search API Adminキーの値を設定ください。あとはazure-search-ta-ui.htmlにアクセスいただければ上記のようなUIが出力されるはずです。なぜHTML/JSだけではなく間にPHPを挟んでいるのかについて、Azure SearchのAnalyze APIや管理系APIリクエストに位置付けられており、管理系APIはvia CORSでのリクエストを受け付けていないからである。
$ git clone https://github.com/yokawasa/azure-search-ta.git` $ vi azure-search-ta/ui/analyze-api.php $azureSearchAccount=""; $azureSearchApiKey = ""; Command-Line Tool 1. インストールと設定 pipでazure-search-taパッケージをインストール。既に古いバージョンをインストール済みでアップデートする際は――upgradeをつけて実行ください。
$ pip install --user azure-search-ta 次に、search.confにお使いのAzure Searchカウント名とAzure Search API Adminキーの値を設定ください。
# Azure Search Service Name ( never put space before and after = ) SEARCH_SERVICE_NAME= # Azure Search API Admin Key ( never put space before and after = ) SEARCH_API_KEY= 2....</p></section><footer class=entry-footer><span title='2017-05-13 00:00:00 +0000 UTC'>May 13, 2017</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Azure Search Text Analyzer Tools - azure-search-ta" href=https://unofficialism.info/posts/azure-search-analyzer-test-with-azure-search-ta/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>azuresshconfig has been dockerized</h2></header><section class=entry-content><p>UPDATED 2017-02-15: changed docker run command example due to Issue#4
以前「azuresshconfigの紹介 – Azure上でのSSH生活を少しだけ快適にする」の投稿でazuresshconfigの紹介をさせていただいたが、ツールをリリースして以来、数少ない貴重な利用者様からインストールがコケるんだけど何とかしろというクレームをいただいていた。そこでインストールマニュアルを充実させようかとか、インストーラーをプラットフォーム別に充実させようかとか考えたものの、ここは流行りのコンテナ実行できるようしたほうがいいだろうということでDocker対応することにした。
今回の対応によりpipインストールや、プラットフォーム別にprerequisiteなランタイム、ヘッダファイル、ライブラリといった面倒なインストールが不要となり、Mac、Windows、Linux(Ubuntu、CentOS、その他distro)関係なくシンプルにdocker runコマンドでの実行が可能となった。
しかも超軽量LinuxディストリビューションであるAlpine Linuxの上にPythonランタイムとツールを載せているだけであるためサイズはたったの155MBとかなり軽め
$ docker images azuresshconfig REPOSITORY TAG IMAGE ID CREATED SIZE azuresshconfig latest 7488bef4343f 7 minutes ago 155 MB 実行例 $ docker run -v $HOME:/root --rm -it yoichikawasaki/azuresshconfig \ --output stdout --user yoichika --identityfile ~/.ssh/id_rsa > $HOME/.ssh/config Dockerfileをダウンロードしてビルド・実行はこちら
$ curl https://raw.githubusercontent.com/yokawasa/azure-ssh-config/master/Dockerfile -o Dockerfile $ docker build -t azuresshconfig . $ docker run -v $HOME:/root --rm -it yoichikawasaki/azuresshconfig \ --output stdout --user yoichika --identityfile ~/....</p></section><footer class=entry-footer><span title='2017-02-05 00:00:00 +0000 UTC'>February 5, 2017</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to azuresshconfig has been dockerized" href=https://unofficialism.info/posts/azuresshconfig-has-been-dockerized/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Logstash plugins for Microsoft Azure Services</h2></header><section class=entry-content><p>Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite destinations. Here is a list of logstash plugins for Microsoft Azure Services.
Plugin Name Target Azure Services Note logstash-input-azureeventhub EventHub Logstash input plugin reads data from specified Azure Event Hubs logstash-input-azureblob Blob Storage Logstash input plugin that reads and parses data from Azure Storage Blobs logstash-input-azuretopic Service Bus Topic Logstash input plugin reads messages from Azure Service Bus Topics logstash-input-azuretopicthreadable Service Bus Topic Logstash input plugin reads messages from Azure Service Bus Topics using multiple threads logstash-output-applicationinsights Application Insights Logstash output plugin that store events to Application Insights logstash-input-azurewadtable Table Storage Logstash input plugin for Azure Diagnostics....</p></section><footer class=entry-footer><span title='2016-12-29 00:00:00 +0000 UTC'>December 29, 2016</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Logstash plugins for Microsoft Azure Services" href=https://unofficialism.info/posts/logstash-plugins-for-azure-services/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Detecting faces in Video contents using Azure Cognitive Services Face API</h2></header><section class=entry-content><p>過去に本ブログでビデオコンテンツを切り口とした音声認識やOCR技術を利用したデモを紹介したが、ここではビデオコンテンツの中の人物出現箇所に連動して人物名を字幕で表示させるデモとその実装方法を紹介したい。人物識別にはAzureのCognitive ServicesのFace APIを使っていて、これで動画の中に出現する顔の検出を行い、予め登録している人物リストとのマッチングにより実現している。 Cognitive Serivcesとは視覚、音声、言語、知識などマイクロソフトがこれまで研究を通じて開発してきたさまざまな要素技術をAPIとして提供しているサービスのことで、最近巷で人工知能（AI）だとかインテリジェンスとかいうキーワードをよく耳にするのではないかと思うがAzure利用シナリオでそういったインテリジェンス（知能/知性）を兼ね備えたアプリを作る場合は間違いなく中核となるサービスの1つである。Face APIはその中でも顔の検出・識別や、顔にまつわる感情、特徴などメタデータ抽出に特化したAPIである。
demo site source code 主要テクノロジーと機能 下図は今回のデモ作成のために行っている処理フローと主要テクノロジーを表している。やっていることは大きく分けて3つ: (1) 動画コンテンツをAzure Media Encoder Standardを使ってフレームごとの静止画像の作成, (2) Cognitive ServicesのFace APIを使って1より得られた静止画像から顔の検出を行い予め登録している人物リストとマッチング（最も類似度が高いものを本人とみなす）して人物を識別, (3) 2で得られた各フレーム中の人物情報を時間順に並べて字幕(Closed Caption)用のデータファイルを生成。以下、各処理の詳細について説明する。
1. Azure Media Encoder Standardでフレームごとの静止画生成 残念ながらFace APIはビデオコンテンツから直接顔検出することができないため、一旦ビデオコンテンツから各フレームごとの静止画を生成してその静止画を対象に処理を行う必要がある。ここでは各フレームごとの静止画生成にAzure Media Encoder Standard（MES）を利用する。MESを使うことでエンコードタスクとしてビデオコンテンツに対して様々な処理を行うことができるのだが、MESにはそのエンコードタスクの１つとしてサムネイル生成のためのタスクが用意されており、今回はこのサムネール生成タスクを利用する。他のエンコードタスク同様にサムネイル生成タスクについてもプリセットと呼ばれるエンコードに必要な情報を記述した XML または JSON形式ファイルを用意する必要がある。今回は1秒フレームごとにJPEG形式の静止画（サムネイル）を生成するために次のようなプリセット（amsmp-thumbnail-config.json）を用意した。
{ "Version": 1.0, "Codecs": [ { "Start": "00:00:00", "Step": "00:00:01", "Type": "JpgImage", "JpgLayers": [ { "Quality": 90, "Type": "JpgLayer", "Width": 640, "Height": 360 } ] } ], "Outputs": [ { "FileName": "{Basename}_{Index}{Extension}", "Format": { "Type": "JpgFormat" } } ] } MESによるサムネイル処理実行方法やプリセットの詳細については「Media Encoder Standard を使用した高度なエンコード」や同ページの「サムネイルを生成する」項を参照ください。尚、今回のサムネイル生成のためのエンコーディング処理は小生自作の「azure-media-processor-java」を利用してバッチ実行している。...</p></section><footer class=entry-footer><span title='2016-12-18 00:00:00 +0000 UTC'>December 18, 2016</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Detecting faces in Video contents using Azure Cognitive Services Face API" href=https://unofficialism.info/posts/azure-media-cognitive-demos-video-frames-face-recognition/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Collecting events into Azure Functions and triggering your custom code using fluent-plugin-azurefunctions</h2></header><section class=entry-content><p>In this article, I’d like to introduces a solution to collect events from various sources and send them into HTTP Trigger function in Azure Functions using fluent-plugin-azurefunctions. Triggers in Azure Functions are event responses used to trigger your custom code. HTTP Trigger functions allow you to respond to HTTP events sent from fluentd and cook them into whatever you want!
[note] Azure Functions is a (“serverless”) solution for easily running small pieces of code, or “functions,” in Azure....</p></section><footer class=entry-footer><span title='2016-11-27 00:00:00 +0000 UTC'>November 27, 2016</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Collecting events into Azure Functions and triggering your custom code using fluent-plugin-azurefunctions" href=https://unofficialism.info/posts/fluent-plugin-azurefunctions/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://unofficialism.info/categories/azure/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://unofficialism.info>Yoichi Kawasaki</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>