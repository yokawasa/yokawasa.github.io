<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Azure | unofficialism</title>
<meta name=keywords content><meta name=description content="Yoichi Kawasaki yokawasa.github.io"><meta name=author content="Yoichi Kawasaki"><link rel=canonical href=https://yokawasa.github.io/categories/azure/><link crossorigin=anonymous href=https://yokawasa.github.io/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://yokawasa.github.io/profile.png><link rel=icon type=image/png sizes=16x16 href=https://yokawasa.github.io/profile.png><link rel=icon type=image/png sizes=32x32 href=https://yokawasa.github.io/profile.png><link rel=apple-touch-icon href=https://yokawasa.github.io/profile.png><link rel=mask-icon href=https://yokawasa.github.io/profile.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://yokawasa.github.io/categories/azure/index.xml><link rel=alternate hreflang=en href=https://yokawasa.github.io/categories/azure/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Azure | unofficialism"><meta property="og:description" content="Yoichi Kawasaki yokawasa.github.io"><meta property="og:type" content="website"><meta property="og:url" content="https://yokawasa.github.io/categories/azure/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Azure | unofficialism"><meta name=twitter:description content="Yoichi Kawasaki yokawasa.github.io"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yokawasa.github.io/ accesskey=h title="unofficialism (Alt + H)">unofficialism</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://yokawasa.github.io/about title=about><span>about</span></a></li><li><a href=https://yokawasa.github.io/posts title=posts><span>posts</span></a></li><li><a href=https://yokawasa.github.io/works title=works><span>works</span></a></li><li><a href=https://yokawasa.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://yokawasa.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://yokawasa.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://yokawasa.github.io/categories/>Categories</a></div><h1>Azure</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>Azure Insights REST APIを使ってAzure各リソースのメトリックを抽出する</h2></header><div class=entry-content><p>ARMとAzure Insights API Azure上のさまざまなサービスのメトリック情報をAPI経由で取得したい。そういうことであればAzure Service Management APIを使えばいいじゃないかという声が聞こえてきそうなところだが実は既にこのやり方は時代遅れとなっていることをご存じだろうか？ 2014年5月ごろ？に登場したAzureの新しい考え方にResource、ResourceGroup、Azure Resource Managerというものがある。簡単な説明すると、Azure上のPaaSインスタンス、仮想マシンなどすべての管理可能な資源をリソース(Resource)とよばれる単位に細分化し、それらをグループ化したものがResourceGroup、そして全てのリソースはAzure Resource Manager（以下ARM）というもので管理可能になっている。そしてこのARMで管理可能な世界のリソース群に紐づくメトリックデータはAzure Insights APIで取得可能となっている。本記事ではさまざまなリソースの中でもWeb Appsに絞って、Azure Insights REST API (Metric)を使ってそのメトリックを取得する方法について紹介する。
ARM Explorerでどのメトリックが取得可能なのか確認する ARM Explorer (https://resources.azure.com/) をご存じだろうか？　これはその名の通りAzure上の全てのリソース（ご利用のサブスクリプションに紐づく全てのリソース）のエクスプローラーであり、これを使うことでこのARM管理下の世界のすべてのリソースをエクスプローラービューで閲覧することができる。このARM Explorerで閲覧可能な各リソースの情報の中にmetricdefinitionsというものがあって、これにはそのリソースに対して指定可能なメトリックの種類やその定義情報などが格納されている。リソースのメトリック取得をする際は、まずはARM Explorerで目的のリソースのmetricdefinitionsから指定可能なメトリックの種類を把握してからAPIリクエストを組み立てていただければと思う。ARM Explorerを使って本記事で取得対象としているWeb Apps（ここではサイト名yoichikademoを対象）のmetricdefinitionsを閲覧しているのが以下のスクリーンショットになる。
Azure Insights REST APIメトリック取得インターフェース Azure Insights APIには次のような(1)メトリック定義一覧の取得と(2)対象リソースのメトリック情報取得の2つのインターフェースがある。当然ながらメトリックの取得には(2)のインターフェースを使用する。
(1)メトリック定義一覧取得
GET https://management.azure.com /subscriptions/{-id}/resourceGroups/{resource-group-name}/providers/{resource-provider-namespace}/{resource-type}/{resource-name}/metricDefinitions [Parameters] api-version={api-version} $filter={filter} (2)メトリック情報取得
GET https://management.azure.com /subscriptions/{-id}/resourceGroups/{resource-group-name}/providers/{resource-provider-namespace}/sites/{sitename}/metrics [Parameters] api-version={api-version} $filter={filter} APIの共通部分は下記の通り。Azure Insights APIへの全ての要求はAzure Active Directoryを使用して認証する必要があり、この認証により得られたトークンを各APIリクエストのAuthorizationヘッダに指定する必要がある。トークン取得の方法にはPowerShellを使用した方法とAzure管理ポータルを使用して認証する2つの方法がある。詳しくは「Azure インサイト要求を認証する」を参照ください。
{api-version}：“2014-04-01” {subscription-id} ： サブスクリプションID {resource-group-name}： リソースグループを指定。詳細は「リソースグループを使用した Azure リソースの管理」を参照ください Acceptヘッダー："application/json"を指定。これを指定しない場合、結果はXMLで返却される AuthorizationヘッダーにAzure Active Directory から取得する JSON Web Token（JWT） に設定する。詳細は「Azure インサイト要求を認証する」を参照ください 実際のメトリクス取得APIでは$filterパラメータの付与が必要となる。$filterには主にメトリックの種類(name....</p></div><footer class=entry-footer>&lt;span title='2015-08-15 00:00:00 +0000 UTC'>August 15, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;1 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Azure Insights REST APIを使ってAzure各リソースのメトリックを抽出する" href=https://yokawasa.github.io/posts/getting-resource-metrics-with-azure-insights-rest-api/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>DocumentDBをAzure Searchのデータソースとして利用する</h2></header><div class=entry-content><p>Azure Searchのインデックス更新方法には大きく分けてPUSHとPULLの２種類ある。PUSHは直接Indexing APIを使ってAzure SearchにコンテンツをPOSTして更新。PULLは特定データソースに対してポーリングして更新で、Azure Searchの場合、DocumentDBとSQL Databaseの2種類のデータソースを対象にワンタイムもしくは定期的なスケジュール実行が可能となっている。ここではDocumentDBをデータソースとしてインデックスを更新する方法を紹介する。
サンプル構成と処理フローの説明 データソースにDocumentDBを利用する。データ「DOCUMENTDB PYTHON SDKとFEEDPARSERで作る簡易クローラー」においてクローリングされDocumentDBに保存されたブログ記事データを使用する。そしてDocumentDBを定期的にポーリングを行い更新があったレコードのみをAzure Searchインデックスに反映するためにDocumentDBインデクサーを設定する。全体構成としては下記の通りとなる。
DocumentDBと更新先検索インデックスのフィールドのマッピング DocumentDBをデータソースとしてAzure Searchインデックスに更新を行うためDocumentDBの参照先コレクションのフィールドと更新先Azure Searchインデックスのフィールドをマッピングを行う。マッピングはデータソース定義中のDocumentDB参照用Queryで行う。Azure SearchインデックスにインジェストするフィールドをDocumentDBのSELECTクエリー指定するのだが、Azure SearchとDocumentDBのフィールドが異なる場合は下図のようにSELECT “Docdbフィールド名” AS “Searchフィールド名"でインジェスト先フィールド名を指定する。データソース定義については後述の設定内容を確認ください。
Configuration 以下１～４のステップでデータソースの作成、検索インデックスの作成、インデクサーの作成、インデクサーの実行を行う。
(1) データソースの作成
credential.connectionStringで接続先DocumentDB文字列と対象データベースの指定を行う。container.(name|query)で対象コレクション名と参照用SELECT文を指定する。SELECT文はDocumentDBとインジェスト先Azure Searchのフィールドセット（フィールド名と数）が同じであれば省略可。詳細はこちらを参照。
#!/bin/sh SERVICE_NAME='&lt;Azure Search Service Name>' API_VER='2015-02-28-Preview' ADMIN_KEY='&lt;API KEY>' CONTENT_TYPE='application/json' URL="https://$SERVICE_NAME.search.windows.net/datasources?api-version=$API_VER" curl -s\ -H "Content-Type: $CONTENT_TYPE"\ -H "api-key: $ADMIN_KEY"\ -XPOST $URL -d'{ "name": "docdbds-article", "type": "documentdb", "credentials": { "connectionString": "AccountEndpoint=https://&lt;DOCUMENTDB_ACCOUNT>.documents.azure.com;AccountKey=&lt;DOCUMENTDB_MASTER_KEY_STRING>;Database=&lt;DOCUMENTDB_DBNAME>" }, "container": { "name": "article_collection", "query": "SELECT s.id AS itemno, s.title AS subject, s.content AS body, s....</p></div><footer class=entry-footer>&lt;span title='2015-06-28 00:00:00 +0000 UTC'>June 28, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to DocumentDBをAzure Searchのデータソースとして利用する" href=https://yokawasa.github.io/posts/levelage-documentdb-as-azuresearch-datasource/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>DocumentDB Python SDKとfeedparserで作る簡易クローラー</h2></header><div class=entry-content><p>DocumentDB Python SDKとfeedparserを使って簡易クローラーを作りましょうというお話。ここではDocumentDBをクローリング結果の格納先データストアとして使用する。クロール対象はAzure日本語ブログのRSSフィード、これをfeedparserを使ってドキュメント解析、必要データの抽出、そしてその結果を今回使用するpydocumentdbというDocumentDB Python SDKを使ってDocumentDBに格納するというワークフローになっている。
DocumentDB Python SDK - pydocumentdb Azureで提供されているどのサービスにもあてはまることであるが、DocumentDBを操作するための全てのインターフェースはREST APIとして提供されておりREST APIを内部的に使用してマイクロソフト謹製もしくは個人のコントリビューションによる複数の言語のSDKが用意されている。その中でもpydocumentdbはPython用のDocumentDB SDKであり、オープンソースとしてソースコードは全てGithubで公開されている。
pydocumentdbプロジェクトトップ(Github) pydocumentdbサンプルコード(Github) Azure DocumentDB REST API Reference Pre-Requirementsその１: Python実行環境とライブラリ 実行環境としてPython2.7系が必要となる。また、今回クローラーが使用しているDocumentDB Python SDKであるpydocumentdbとRSSフィード解析ライブラリfeedparserの２つのライブラリのインストールが必要となる。
pydocumentdbインストール
$ sudo pip install pydocumentdb feedparserインストール
$ sudo pip install feedparser ちなみにpipがインストールされていない場合は下記の通りマニュアルもしくはインストーラーを使用してpipをインストールが必要となる
pip マニュアルインストール
# download get-pip.py $ wget https://bootstrap.pypa.io/get-pip.py # run the following (which may require administrator access) $ sudo python get-pip.py # upgrade pip $ sudo pip install -U pip インストーラーを使用...</p></div><footer class=entry-footer>&lt;span title='2015-06-21 00:00:00 +0000 UTC'>June 21, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to DocumentDB Python SDKとfeedparserで作る簡易クローラー" href=https://yokawasa.github.io/posts/crawler-with-documentdb-python-sdk-and-feedparser/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Wikipediaデータベースを元にAzure Searchインデックスを生成する</h2></header><div class=entry-content><p>Wikipediaのコンテンツは Creative Commons Licenseおよび GNU Free Documentation Licenseの下にライセンスされておりWikipedia財団は再配布や再利用のために惜しげもなくこの貴重なデータベースのダンプファイル（XMLファイル）を一般提供している。全文検索の検証で大量のデータが必要なときこのWikipediaのような生きたデータを使えるのは非常に有りがたい。これはこのWikipediaデータベースダンプ（日本語）を元にAzure Searchインデックスを生成してみましょうというお話。
Wikipedia:データベースダウンロード ウィキメディア財団による全プロジェクトのデータベース・ダンプ Wikipedia日本語版のダンプデータレポジトリ(日本語最新版) 利用するWikipedia XMLファイルとその定義 最新版日本語レポジトリには複数のXMLファイルが用意されているがここでは全ページのタイトル、ディスクリプションといった要約データを集約しているファイルjawiki-latest-abstract.xmlを利用する。XMLのフォーマットは次のとおり。この中からtitle, url, abstractを抽出してAzure Searchに投入する。
&lt;doc> &lt;title>Wikipedia: 自然言語&lt;/title> &lt;url>http://ja.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E&lt;/url> &lt;abstract>自然言語（しぜんげんご、）とは、人間によって日常の意思疎通のために用いられる、文化的背景を持って自然に発展してきた記号体系である。大別すると音声に>よる話し言葉と文字や記号として書かれる書き言葉がある。&lt;/abstract> &lt;links> &lt;sublink linktype="nav">&lt;anchor>概要&lt;/anchor>&lt;link>http://ja.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E#.E6.A6.82.E8.A6.81&lt;/link>&lt;/sublink> &lt;sublink linktype="nav">&lt;anchor>関連項目&lt;/anchor>&lt;link>http://ja.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E#.E9.96.A2.E9.80.A3.E9.A0.85.E7.9B.AE&lt;/link>&lt;/sublink> &lt;/links> &lt;/doc> 尚、実際にダウンロードしてみるとわかると思うがこのファイルはサイズが比較的大きく集約されているドキュメント数も実に多い。カウントしてみたところ現時点（2015/06/09）で969541　件あった。Azure Searchの料金プランのうちFreeプランは最大ドキュメント数が10,000であることからここで利用する料金プランはFreeではなく標準プランを選択する必要がある。
Index Schema インデックス名はwikipedia、フィールドはキーフィールドのためのitemidフィールドと上記wikipedia XMLファイルのtitle, url, abstractを格納するための3フィールドを定義。
{ "name": "wikipedia", "fields": [ { "name":"itemid", "type":"Edm.String", "key": true, "searchable": false }, { "name":"title", "type":"Edm.String", "filterable":false, "sortable":false, "facetable":false}, { "name":"abstract", "type":"Edm.String", "filterable":false, "sortable":false, "facetable":false, "analyzer":"ja.lucene" }, { "name":"url", "type":"Edm.String", "sortable":false, "facetable":false } ] } Azure Search投入用JSONデータの生成 Wikipedia XMLファイルからAzure Search投入用のJSONデータを生成するスクリプト(xml2json....</p></div><footer class=entry-footer>&lt;span title='2015-06-09 00:00:00 +0000 UTC'>June 9, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;2 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to Wikipediaデータベースを元にAzure Searchインデックスを生成する" href=https://yokawasa.github.io/posts/putting-wikipedia-data-into-azure-search/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>cUrlコマンドで始める簡単Azure Search</h2></header><div class=entry-content><p>cUrlはUNIX/Linux系では有名なURLを使ったデータ送受信コマンドで手軽にREST系処理を実行するときにとても重宝している。そんなcUrlコマンドを使ってAzure Searchをお手軽に使ってみようというお話。
はじめに まだの人はAzureポータルよりAzure Searchサービスを作成してください。「ポータルでの Azure Search サービスの作成」に優しく手順が書かれているのでご参考に。料金プランは無料と標準プランがあるがテストであれば無料プランで十分。まずはAPIキーまで取得ください。API実行のためにはAPIキーが必要。
cURLでSearch Service REST APIを実行 Search Service REST APIの中からいくつか代表的なAPIをピックアップしてcUrlでクエリを組み立ててみる。ここではインデックス新規作成、そこにいくつかドキュメントを追加、そしてドキュメントを検索する・・といった基本的なシナリオを実行する。ポイントとしてはcUrlの-Hオプションでヘッダ定義、-XオプションでHTTPメソッド指定、-dオプションでリクエストボディを指定する・・・といったところ。尚、下記サンプルでは現時点（2015-06-05）で最新のAPIバージョン2015-02-28-Previewを使用している。
1. インデックス新規作成 articlesという名前のブログ記事を格納するためのインデックスを作成する。インデックス生成にはCreate Index (Azure Search Service REST API)を利用する。
#!/bin/sh SERVICE_NAME='&lt;Azure Search Service Name>' API_VER='2015-02-28-Preview' ADMIN_KEY='&lt;API KEY>' CONTENT_TYPE='application/json' URL="https://$SERVICE_NAME.search.windows.net/indexes?api-version=$API_VER" curl -s\ -H "Content-Type: $CONTENT_TYPE"\ -H "api-key: $ADMIN_KEY"\ -XPOST $URL -d'{ "name": "articles", "fields": [ { "name":"itemid", "type":"Edm.String", "key": true, "searchable": false }, { "name":"title", "type":"Edm.String", "filterable":false, "sortable":false, "facetable":false}, { "name":"content", "type":"Edm.String", "filterable":false, "sortable":false, "facetable":false, "analyzer":"ja....</p></div><footer class=entry-footer>&lt;span title='2015-06-05 00:00:00 +0000 UTC'>June 5, 2015&lt;/span>&amp;nbsp;·&amp;nbsp;3 min&amp;nbsp;·&amp;nbsp;Yoichi Kawasaki</footer><a class=entry-link aria-label="post link to cUrlコマンドで始める簡単Azure Search" href=https://yokawasa.github.io/posts/getting-started-azure-search-with-curl/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://yokawasa.github.io/categories/azure/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://yokawasa.github.io/>unofficialism</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>